{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2db1bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- 0. Environment Setup & Offline Preparation ---\n",
    "\n",
    "# Standard Imports\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import collections # For deque in parenthesis removal\n",
    "import fitz # PyMuPDF for PDF processing\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "from transformers.utils.quantization_config import BitsAndBytesConfig\n",
    "from transformers.training_args import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "from datasets import Dataset # Hugging Face datasets library\n",
    "import kagglehub\n",
    "\n",
    "# Set device for PyTorch\n",
    "device = \"cuda\" if torch and torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e263db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for file paths and model configurations\n",
    "BASE_INPUT_DIR = './kaggle/input/make-data-count-finding-data-references'\n",
    "ARTICLE_TRAIN_DIR = os.path.join(BASE_INPUT_DIR, 'train')\n",
    "ARTICLE_TEST_DIR = os.path.join(BASE_INPUT_DIR, 'test')\n",
    "\n",
    "# Define directories for articles in train and test sets\n",
    "LABELED_TRAINING_DATA_CSV_PATH = os.path.join(BASE_INPUT_DIR, 'train_labels.csv')\n",
    "\n",
    "# Define the base model path\n",
    "QWEN_BASE_MODEL_PATH = kagglehub.model_download(\"qwen-lm/qwen-3/transformers/0.6b\")\n",
    "\n",
    "# Output directory for the fine-tuned model and results\n",
    "BASE_OUTPUT_DIR = \"./kaggle/working\"\n",
    "FINE_TUNED_MODEL_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, \"qwen_finetuned_dataset_classifier\")\n",
    "FINAL_RESULTS_CSV_PATH = os.path.join(BASE_OUTPUT_DIR, \"article_dataset_classification.csv\")\n",
    "\n",
    "inference_model = None\n",
    "inference_tokenizer = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "3d64ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOI_PATTERN to handle optional 'https://doi.org/' prefix\n",
    "# and to allow EITHER '/' or '.' as the separator between the registrant code and suffix.\n",
    "# This addresses the case like '10.1234.data.archive.'\n",
    "\n",
    "# Explanation of the new pattern:\n",
    "# \\b(                                : Start of the main capturing group for the entire DOI string.\n",
    "#   (?:                             : Start of optional non-capturing group for the URL prefix.\n",
    "#     https?:\\s*//\\s*doi\\s*\\.\\s*org\\s*/\\s* : Matches 'http://doi.org/' or 'https://doi.org/'\n",
    "#                                         : allowing for zero or more whitespace characters (\\s*)\n",
    "#                                         : between each part (e.g., 'https://\\ndoi.org/').\n",
    "#   )?                              : Makes the entire URL prefix optional.\n",
    "#   10\\.\\d{4,9}[./]                 : Matches the standard DOI prefix (e.g., \"10.1002/\")\n",
    "#                                   : BUT now allows EITHER a '/' or a '.' as the separator\n",
    "#                                   : after the 4-9 digits. This is the key change.\n",
    "#   [\\s\\S]*?                        : Matches any character (including newlines and spaces)\n",
    "#                                   : zero or more times, *non-greedily*. This consumes the DOI suffix.\n",
    "# )                                 : End of the main capturing group. This group will contain the full DOI\n",
    "#                                   : including the optional URL prefix and any internal newlines.\n",
    "# (?=                                : Positive lookahead for termination (same as before):\n",
    "#   \\s*\\n\\s*[A-Z]                   : Newline followed by a Capital letter.\n",
    "#   | \\n{2,}                        : Two or more consecutive newlines.\n",
    "#   | [.?!;]\\s*[A-Z]                : Sentence-ending punctuation followed by a Capital letter.\n",
    "#   | \\s{2,}                        : Two or more consecutive spaces.\n",
    "#   | \\b(?:The|This|And|In|For|With|A|An|But|Or|So|If|As|By|On|At|From|To)\\b : Common sentence starters.\n",
    "#   | $                             : End of the string.\n",
    "# )\n",
    "#DOI_PATTERN_ROBUST_MULTILINE = r'\\b((?:https?:\\s*//\\s*doi\\s*\\.\\s*org\\s*/\\s*)?10\\.\\d{4,9}[./][\\s\\S]*?)(?=\\s*\\n\\s*[A-Z]|\\n{2,}|[.?!;]\\s*[A-Z]|\\s{2,}|\\b(?:The|This|And|In|For|With|A|An|But|Or|So|If|As|By|On|At|From|To)\\b|$)'\n",
    "#DOI_PATTERN_ROBUST_MULTILINE = r'\\b((?:https?:\\s*//\\s*doi\\s*\\.\\s*org\\s*/\\s*)?10\\.\\d{4,9}[./][\\s\\S]*?)(?=\\s*\\n\\s*[A-Z]|\\n{2,}|[.?!;]\\s*[A-Z]|\\s{2,}|\\b(?:The|This|And|In|For|With|A|An|But|Or|So|If|As|By|On|At|From|To)\\b|$)'\n",
    "DOI_PATTERN_ROBUST_MULTILINE = r'\\b((?:https?:\\s*//\\s*doi\\s*\\.\\s*org\\s*/\\s*)?10\\.\\s*\\d{4,9}[./][\\s\\S]*?)(?=\\s*\\n\\s*[A-Z]|\\n{2,}|[.?!;]\\s*[A-Z]|\\s{2,}|\\b(?:The|This|And|In|For|With|A|An|But|Or|So|If|As|By|On|At|From|To)\\b|$)'\n",
    "\n",
    "\n",
    "def clean_doi_match(match_obj: re.Match) -> str:\n",
    "    \"\"\"\n",
    "    Replacement function for re.sub().\n",
    "    Takes a match object (which contains the full matched DOI, potentially with newlines\n",
    "    and the optional 'https://doi.org/' prefix) and removes all internal whitespace\n",
    "    characters to produce a clean, continuous DOI string.\n",
    "    \"\"\"\n",
    "    matched_doi = match_obj.group(1) # Get the content of the first (and only) capturing group\n",
    "    cleaned_doi = re.sub(r'\\s+', '', matched_doi) # Remove all whitespace\n",
    "\n",
    "    # Prepend 'https://doi.org/' if it was not already included\n",
    "    if not cleaned_doi.startswith('https://doi.org/'):\n",
    "        cleaned_doi = 'https://doi.org/' + cleaned_doi\n",
    "    return cleaned_doi\n",
    "\n",
    "def clean_doi_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the input text by removing unwanted characters and normalizing whitespace.\n",
    "    \"\"\"\n",
    "    # Check if the input text is empty or None\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # The re.DOTALL flag is essential here because `[\\s\\S]` is used.\n",
    "    return re.sub(DOI_PATTERN_ROBUST_MULTILINE, clean_doi_match, text, flags=re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fd5e3668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text after cleaning DOIs:\n",
      "\n",
      "This article discusses various research methods.\n",
      "A key reference is found via its DOI: https://doi.org/10.1002/(some.journal)-1234.5678.\n",
      "This is a new sentence starting here.\n",
      "\n",
      "Another important dataset has the DOI: https://doi.org/10.1234.data.archive.9876.5432. The data was analyzed.\n",
      "\n",
      "Yet another: https://doi.org/10.1234/multi.line.prefix.\n",
      "And a final one: https://doi.org/10.9999/last.one.\n",
      "\n",
      "\n",
      "Text after cleaning DOIs 2:\n",
      "\n",
      "Here's a DOI: https://doi.org/10.1234/test.doi. This is a new sentence.\n",
      "Another DOI: https://doi.org/10.5678/another.doi. And a third: https://doi.org/10.9876/third.doi\n",
      "\n",
      "[24] This is a new sentence starting here with a bullet point.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "test_pdf_text = \"\"\"\n",
    "This article discusses various research methods.\n",
    "A key reference is found via its DOI: 10.1002/\n",
    "(some.journal)-1234.5678.\n",
    "This is a new sentence starting here.\n",
    "\n",
    "Another important dataset has the DOI: https://doi.org/10.\n",
    "1234.data.archive.\n",
    "9876.5432. The data was analyzed.\n",
    "\n",
    "Yet another: https://\n",
    "doi.org/10.1234/\n",
    "multi.line.\n",
    "prefix.\n",
    "And a final one: 10.9999/last.one.\n",
    "\"\"\"\n",
    "\n",
    "# The re.DOTALL flag is essential here because `[\\s\\S]` is used.\n",
    "cleaned_text = clean_doi_text(test_pdf_text)\n",
    "\n",
    "print(\"\\nText after cleaning DOIs:\")\n",
    "print(cleaned_text)\n",
    "\n",
    "# Test case: DOI with prefix on a single line\n",
    "test_pdf_text_2 = \"\"\"\n",
    "Here's a DOI: https://doi.org/10.1234/test.doi. This is a new sentence.\n",
    "Another DOI: 10.5678/another.doi. And a third: https://doi.org/10.9876/third.doi\n",
    "\n",
    "[24] This is a new sentence starting here with a bullet point.\n",
    "\"\"\"\n",
    "# print(\"\\nOriginal PDF Text 2:\")\n",
    "# print(test_pdf_text_2)\n",
    "cleaned_text_2 = clean_doi_text(test_pdf_text_2)\n",
    "print(\"\\nText after cleaning DOIs 2:\")\n",
    "print(cleaned_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "2e50e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Information Extraction (IE) - Dataset Identification ---\n",
    "\n",
    "# Regex patterns for common dataset identifiers\n",
    "# DOI_PATTERN = r'10\\.\\d{4,5}/[-._;()/:A-Za-z0-9\\u002D\\u2010\\u2011\\u2012\\u2013\\u2014\\u2015]+'\tDOI_PATTERN\n",
    "# DOI_PATTERN = r'10\\.\\s?\\d{4,5}\\/[-._()<>;\\/:A-Za-z0-9]+\\s?(?:(?![A-Z]+)(?!\\d{1,3}\\.))+[-._()<>;\\/:A-Za-z0-9]+'\n",
    "DOI_PATTERN = r'\\bhttps://doi.org/10\\.\\d{4,5}\\/[-._\\/:A-Za-z0-9]+'\n",
    "EPI_PATTERN = r'\\bEPI[-_A-Z0-9]{2,}'\n",
    "SAM_PATTERN = r'\\bSAMN[0-9]{2,}'          # SAMN07159041\n",
    "IPR_PATTERN = r'\\bIPR[0-9]{2,}'\n",
    "CHE_PATTERN = r'\\bCHEMBL[0-9]{2,}'\n",
    "PRJ_PATTERN = r'\\bPRJ[A-Z0-9]{2,}'\n",
    "E_G_PATTERN = r'\\bE-[A-Z]{4}-[0-9]{2,}'   # E-GEOD-19722 or E-PROT-100\n",
    "ENS_PATTERN = r'\\bENS[A-Z]{4}[0-9]{2,}'\n",
    "CVC_PATTERN = r'\\bCVCL_[A-Z0-9]{2,}'\n",
    "EMP_PATTERN = r'\\bEMPIAR-[0-9]{2,}'\n",
    "PXD_PATTERN = r'\\bPXD[0-9]{2,}'\n",
    "HPA_PATTERN = r'\\bHPA[0-9]{2,}'\n",
    "SRR_PATTERN = r'\\bSRR[0-9]{2,}'\n",
    "GSE_PATTERN = r'\\b(GSE|GSM|GDS|GPL)\\d{4,6}\\b' # Example for GEO accession numbers (e.g., GSE12345, GSM12345)\n",
    "GNB_PATTERN = r'\\b[A-Z]{1,2}\\d{5,6}\\b' # GenBank accession numbers (e.g., AB123456, AF000001)\n",
    "CAB_PATTERN = r'\\bCAB[0-9]{2,}'\n",
    "\n",
    "# Combine all patterns into a list\n",
    "DATASET_ID_PATTERNS = [\n",
    "    DOI_PATTERN,\n",
    "    EPI_PATTERN,\n",
    "    SAM_PATTERN,\n",
    "    IPR_PATTERN,\n",
    "    CHE_PATTERN,\n",
    "    PRJ_PATTERN,\n",
    "    E_G_PATTERN,\n",
    "    ENS_PATTERN,\n",
    "    CVC_PATTERN,\n",
    "    EMP_PATTERN,\n",
    "    PXD_PATTERN,\n",
    "    HPA_PATTERN,\n",
    "    SRR_PATTERN,\n",
    "    GSE_PATTERN,\n",
    "    GNB_PATTERN,\n",
    "    CAB_PATTERN,\n",
    "]\n",
    "\n",
    "# Compile all patterns for efficiency\n",
    "COMPILED_DATASET_ID_REGEXES = [re.compile(p) for p in DATASET_ID_PATTERNS]\n",
    "\n",
    "# Data related keywords to look for in the text\n",
    "# These keywords help to ensure that the text is relevant to datasets\n",
    "DATA_RELATED_KEYWORDS = ['data release', 'download', 'program data', 'data availability', 'the data', 'dataset', 'database', 'repository', 'data source', 'data access', 'data archive']\n",
    "\n",
    "def text_has_dataset_id(text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given text contains any dataset identifier.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to check for dataset identifiers.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if any dataset identifier is found, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    occurrences_with_context: list[str] = []\n",
    "    for regex in COMPILED_DATASET_ID_REGEXES:\n",
    "        if regex.search(text):\n",
    "            text_lower = text.lower()\n",
    "            # Check for specific keywords in the text\n",
    "            if any(keyword in text_lower for keyword in DATA_RELATED_KEYWORDS):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def extract_dataset_ids(text: str, context_chars: int = 100) -> str:\n",
    "    \"\"\"\n",
    "    Extract dataset identifiers with context from the given text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to search for dataset identifiers.\n",
    "        context_chars (int): Number of characters to include before and after the match for context.\n",
    "        \n",
    "    Returns:\n",
    "        list[str]: A list of extracted dataset identifiers with context.\n",
    "    \"\"\"\n",
    "    # start_sep = \"<dataset_id_with_context>\"\n",
    "    # end_sep = \"</dataset_id_with_context>\"\n",
    "    # mid_sep = end_sep+start_sep\n",
    "    is_small_context = len(text) < context_chars * 2\n",
    "    dataset_ids: list[str] = []\n",
    "    occurrences_with_context: list[str] = []\n",
    "    text_lower = text.lower()\n",
    "    if any(keyword in text_lower for keyword in DATA_RELATED_KEYWORDS):\n",
    "        for regex in COMPILED_DATASET_ID_REGEXES:\n",
    "            matches = regex.finditer(text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                dataset_id = text[match.start() : match.end()]\n",
    "                if is_small_context:\n",
    "                    dataset_ids.append(dataset_id)\n",
    "                else:\n",
    "                    extracted_snippet = text[max(0, match.start() - context_chars): match.end() + context_chars ]\n",
    "                    extracted_snippet_lower = extracted_snippet.lower()\n",
    "                    if any(keyword in extracted_snippet_lower for keyword in DATA_RELATED_KEYWORDS):\n",
    "                        occurrences_with_context.append(\"{\" + f'\"dataset_ids\": {[dataset_id]}, context: \"{extracted_snippet}\"' + \"}\")\n",
    "        if dataset_ids:\n",
    "            occurrences_with_context.append(\"{\" + f'\"dataset_ids\": {dataset_ids}, context: \"{text}\"' + \"}\")\n",
    "    \n",
    "    # If no occurrences found, return an empty string\n",
    "    # Otherwise, join the occurrences with a specific separator\n",
    "    if not occurrences_with_context:\n",
    "        return \"\"\n",
    "    return \",\".join(occurrences_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29351aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 12.8/12.8 MB 74.1 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run this line once to download the model\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "bec3b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Load a spaCy model (e.g., 'en_core_web_sm')\n",
    "# python -m spacy download en_core_web_sm \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_sentences_from_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    doc_spacy = nlp(text)\n",
    "    return \"\\n\".join([sent.text.replace('-\\n', '-').replace('_\\n', '_').replace('/\\n', '/').replace('\\n', ' ') for sent in doc_spacy.sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a58f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading ---\n",
    "def load_file_paths(dataset_type_dir: str) -> pd.DataFrame: \n",
    "    pdf_path = os.path.join(dataset_type_dir, 'PDF')\n",
    "    xml_path = os.path.join(dataset_type_dir, 'XML')\n",
    "    dataset_type = os.path.basename(dataset_type_dir)\n",
    "    pdf_files = [f for f in os.listdir(pdf_path) if f.endswith('.pdf')]\n",
    "    xml_files = [f for f in os.listdir(xml_path) if f.endswith('.xml')]\n",
    "    df_pdf = pd.DataFrame({\n",
    "        'article_id': [f.replace('.pdf', '') for f in pdf_files],\n",
    "        'pdf_file_path': [os.path.join(pdf_path, f) for f in pdf_files]\n",
    "    })\n",
    "    df_xml = pd.DataFrame({\n",
    "        'article_id': [f.replace('.xml', '') for f in xml_files],\n",
    "        'xml_file_path': [os.path.join(xml_path, f) for f in xml_files]\n",
    "    })\n",
    "    merge_df = pd.merge(df_pdf, df_xml, on='article_id', how='outer', suffixes=('_pdf', '_xml'), validate=\"one_to_many\")\n",
    "    merge_df['dataset_type'] = dataset_type\n",
    "    return merge_df\n",
    "\n",
    "def read_pdf_text(pdf_path: str) -> str:\n",
    "    \"\"\"Extracts all text from a PDF file using PyMuPDF.\"\"\"\n",
    "    text = \"\"\n",
    "    p1 = None\n",
    "    abstrct_block_found = False\n",
    "    num_blocks = 0\n",
    "    if not fitz:\n",
    "        return text  # Return empty string if fitz is not available\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for page in doc:\n",
    "                # Extract text from the page\n",
    "                textpage = page.get_textpage()\n",
    "                if page.number == 0:\n",
    "                    p1 = get_sentences_from_text(textpage.extractTEXT())\n",
    "                    p1 = p1[:int(len(p1)/2)] + \".\\npotential_dataset_ids: [\"\n",
    "\n",
    "                # Extract text from all blocks that have dataset id's\n",
    "                blocks = textpage.extractBLOCKS()\n",
    "                for block in blocks:\n",
    "                    block_text = get_sentences_from_text(block[4])\n",
    "                    if page.number == 0 and len(block_text) > 100 and \"abstract\" in block_text.lower():\n",
    "                        abstrct_block_found = True\n",
    "                        text += block_text + \".\\npotential_dataset_ids: [\"\n",
    "                    else:\n",
    "                        # if \"essd-9-861-2017\" in block[4]:\n",
    "                        #     print(f\"Found essd-9-861-2017 in block: {len(block[4])}:{block[4]}\")\n",
    "                        # Each block is a tuple, where the 4th element is the text\n",
    "                        # Clean the DOI text in the block\n",
    "                        #block_text = clean_doi_text(block[4].replace('\\u200b', '').replace('/\\n', '/').strip())\n",
    "                        #block_text = clean_doi_text(get_sentences_from_text(block[4]))\n",
    "                        #block_text = get_sentences_from_text(block[4])\n",
    "                        context_chars = min(250, len(block_text))  # Use a minimum\n",
    "                        dataset_ids_found = extract_dataset_ids(block_text, context_chars)  # Extract dataset IDs from the block text\n",
    "                        if dataset_ids_found:\n",
    "                            # Append the dataset IDs found in the block to the text\n",
    "                            num_blocks += 1\n",
    "                            #print(f\"Found dataset IDs in block: {len(dataset_ids_found)}:{dataset_ids_found}\")\n",
    "                            text += dataset_ids_found + \",\"  # Ensure the block text is processed for dataset IDs\n",
    "                    \n",
    "                    # # Check if the block has text and contains a regex match for a dataset_id\n",
    "                    # if block_text and text_has_dataset_id(block_text):\n",
    "                    #     num_blocks += 1\n",
    "                    #     print(f\"Found dataset ID in block: {len(block_text)}:{block_text}\")\n",
    "                    #     # Append the text from the block, removing zero-width spaces and stripping whitespace\n",
    "                    #     text += block_text.strip() + \" \"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
    "\n",
    "    if p1 and not abstrct_block_found:\n",
    "        text = p1 + text\n",
    "\n",
    "    print(f\"Total blocks with data related dataset IDs found: {num_blocks}\")\n",
    "    print(f\"Extracted text from {pdf_path}. Length: {len(text)} characters\")\n",
    "    return text + \"]\"\n",
    "\n",
    "def read_xml_text(xml_file_path: str) -> str:\n",
    "    \"\"\"Reads and concatenates all text content from an XML file.\"\"\"\n",
    "    all_text_parts = []\n",
    "    try:\n",
    "        tree = ET.parse(xml_file_path)\n",
    "        root = tree.getroot()\n",
    "        for element in root.iter():\n",
    "            if element.text:\n",
    "                cleaned_text = element.text.strip()\n",
    "                if cleaned_text:\n",
    "                    all_text_parts.append(cleaned_text)\n",
    "            if element.tail:\n",
    "                cleaned_tail = element.tail.strip()\n",
    "                if cleaned_tail:\n",
    "                    all_text_parts.append(cleaned_tail)\n",
    "        return \" \".join(all_text_parts) if all_text_parts else \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading XML {xml_file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def load_article_text(filepath: str) -> str:\n",
    "    \"\"\"\n",
    "    Loads text content from a single article file (PDF or XML).\n",
    "    Returns the text content of the given file.\n",
    "    \"\"\"\n",
    "    text_content = \"\"\n",
    "\n",
    "    if filepath.endswith(\".pdf\"):\n",
    "        text_content = read_pdf_text(filepath)\n",
    "    elif filepath.endswith(\".xml\"):\n",
    "        text_content = read_xml_text(filepath)\n",
    "\n",
    "    return text_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "5f45bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total blocks with data related dataset IDs found: 1\n",
      "Extracted text from ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_esp.5058.pdf. Length: 4011 characters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'R E S E A R C H A R T I C L E Past, present and future of a meandering river in the Bolivian Amazon basin Kattia Rubi Arnez Ferrel1 | Jonathan Mark Nelson2 | Yasuyuki Shimizu1 | Tomoko Kyuka1 1Graduate School of Engineering, Hokkaido University, Sapporo, Japan 2U.S. Geological Survey, Golden, Colorado, USA Correspondence Kattia Rubi Arnez Ferrel, Graduate School of Engineering, Hokkaido University, Sapporo 060-0808, Japan. \\nEmail: rubikraf@gmail.com Funding information Nitobe School Project Abstract Field observations on small rivers of the Amazon basin are less common due to their remote location and difficult accessibility.\\nHere we show, through remote sensing analysis and field works, the planform evolution and riverbed topography of a small river located in the upper foreland Amazon basin, the Ichilo River.\\nBy tracking plan-form changes over 30 years, we identified the factors that control meander migration rates in the Ichilo River: cutoffs, climate and human interventions.\\nThe data suggest that neck cutoffs are the main controls in the Ichilo River, with an annual density of 0.022 cutoffs/km.\\nIn addition, climate controls have been identified in the form of high-precipitation events that may have promoted cutoffs, an increase in meander migration rate and channel widening.\\nThe width distribution of the Ichilo River is well represented by general extreme value and inverse Gaussian distributions.\\nThe spatio-temporal variability of meandering migration rates in the Ichilo River is analysed in two locations where neck cutoffs are expected.\\nAnalysing the distance across the neck in these two points, we predict the occurrence of a new cutoff.\\nThe combined methodology of bathymetric surveys and structure from motion photogrammetry shows us the Ichilo riverbed topography and banks at high resolution, where two scour holes were identified.\\nFinally, we discuss the impact of planform changes of the Ichilo River on communities that are established along its riverbanks. \\nK E Y W O R D S bathymetric surveys, Bolivian Amazon basin, Ichilo River, meanders, remote sensing, UAV 1 | INTRODUCTION The Amazon basin exhibits a constantly changing landscape m.\\n potential_dataset_ids: [{\"dataset_ids\": [\\'https://doi.org/10.1002/esp.4637\\'], context: \" Environ. \\nJames, M.R., Chandler, J.H., Eltner, A., Fraser, C., Miller, P.E., Mills, J.P. et al. (2019) Guidelines on the use of structure-from-motion photo-grammetry in geomorphic research.\\nEarth Surface Processes and Land-forms, 44(10), 2081–2084.\\nhttps://doi.org/10.1002/esp.4637 \\n[Dataset] Kinzel, P., Nelson, J.M. & Kattia, R.A.F. (2019)\\nBathymetric survey of the Ichilo and Sajta Rivers, near Puerto Villarroel, Bolivia, May 23–24, 2019.\\nU.S. Geological Survey data release.\\nhttps://doi.org/10.5066/P9FW6E8K Lanzoni, S. & Semi\"},{\"dataset_ids\": [\\'https://doi.org/10.5066/P9FW6E8K\\'], context: \"44(10), 2081–2084.\\nhttps://doi.org/10.1002/esp.4637 \\n[Dataset] Kinzel, P., Nelson, J.M. & Kattia, R.A.F. (2019)\\nBathymetric survey of the Ichilo and Sajta Rivers, near Puerto Villarroel, Bolivia, May 23–24, 2019.\\nU.S. Geological Survey data release.\\nhttps://doi.org/10.5066/P9FW6E8K Lanzoni, S. & Seminara, G. (2006)\\nOn the nature of meander instability. Journal of Geophysical Research - Earth Surface, 111(F4), 1–14. \\nhttps://doi.org/10.1029/2005JF000416 Li, J., Grenfell, M.C., Wei, H., Tooth, S. & Ngiem, S. (2020) Chute cutoff-\"},{\"dataset_ids\": [\\'https://doi.org/10.1029/2005JF000416\\'], context: \"erto Villarroel, Bolivia, May 23–24, 2019.\\nU.S. Geological Survey data release.\\nhttps://doi.org/10.5066/P9FW6E8K Lanzoni, S. & Seminara, G. (2006)\\nOn the nature of meander instability. Journal of Geophysical Research - Earth Surface, 111(F4), 1–14. \\nhttps://doi.org/10.1029/2005JF000416 Li, J., Grenfell, M.C., Wei, H., Tooth, S. & Ngiem, S. (2020) Chute cutoff-driven abandonment and sedimentation of meander bends along a fine-grained, non-vegetated, ephemeral river on the Bolivian Alti-plano. \\nGeomorphology, 350, 106917. \\nhttps://d\"},]'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test loading a PDF file\n",
    "#pdf_file_path = os.path.join(ARTICLE_TRAIN_DIR, 'PDF', '10.1002_2017jc013030.pdf')\n",
    "#pdf_file_path = os.path.join(ARTICLE_TRAIN_DIR, 'PDF', '10.1017_rdc.2022.19.pdf')\n",
    "#pdf_file_path = os.path.join(ARTICLE_TRAIN_DIR, 'PDF', '10.1017_s0007123423000601.pdf')\n",
    "#pdf_file_path = os.path.join(ARTICLE_TRAIN_DIR, 'PDF', '10.3389_fcimb.2024.1292467.pdf')\n",
    "pdf_file_path = os.path.join(ARTICLE_TRAIN_DIR, 'PDF', '10.1002_esp.5058.pdf') # This one is big\n",
    "#pdf_file_path = os.path.join(ARTICLE_TRAIN_DIR, 'PDF', '10.1002_esp.5059.pdf') # This one is big\n",
    "pdf_text = read_pdf_text(pdf_file_path)\n",
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0e8ad257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RESEARCH ARTICLE\\nhttps://doi.org/10.1002/2017JC013030\\nAssessing the Variability in the Relationship Between the\\nParticulate Backscattering Coefficient and the Chlorophyll a\\nConcentration From a Global Biogeochemical-Argo Database\\nMarie Barbieux1\\n, Julia Uitz1, Annick Bricaud1, Emanuele Organelli1,2\\n, Antoine Poteau1\\n,\\nCatherine Schmechtig3\\n, Bernard Gentili1, Grigor Obolensky4, Edouard Leymarie1\\n,\\nChristophe Penkerc’h1, Fabrizio D’Ortenzio1\\n, and Herv�e Claustre1\\n1Sorbonne Universit�es, UPMC Univ Paris 06, CNRS, Observatoire Oc�eanologique de Villefranche, Laboratoire\\nd’Oc�eanographie de Villefranche, Villefranche-sur-Mer, France, 2Plymouth Marine Laboratory, Prospect Place, The Hoe,\\nPlymouth, United Kingdom, 3OSU Ecce Terra, UMS 3455, CNRS and Universit�e Pierre et Marie Curie, Paris 6, Paris, France,\\n4ERIC Euro-Argo, 29280 Plouzan�e, France\\nAbstract Characterizing phytoplankton distribution and dynamics in the world’s open oceans requires in\\nsitu observations over a broad range of space and time scales. In addition to temperature/salinity measure-\\nments, Biogeochemical-Argo (BGC-Argo) profiling floats are capable of autonomously observing at high-\\nfrequency bio-optical properties such as the chlorophyll fluorescence, a proxy of the chlorophyll a concen-\\ntration (Chla), the particulate backscattering coefficient (bbp), a proxy of the stock of particulate organic car-\\nbon, and the light available for photosynthesis. We analyzed an unprecedented BGC-Argo database of more\\nthan 8,500 multivariable profiles collected in various oceanic conditions, from subpolar waters to subtropical\\ngyres. Our objective is to refine previously established Chla versus bbp relationships and gain insights into\\nthe sources of vertical, seasonal, and regional variability in this relationship. Despite some regional, seasonal\\nand vertical variations, a general covariation occurs at a global sca <dataset_id_with_context>rom a\\nglobal Biogeochemical-Argo database.\\nJournal of Geophysical Research:\\nOceans, 123, 1229–1250. https://doi.org/10.1002/2017JC013030</dataset_id_with_context>  <dataset_id_with_context>ntribute to\\nmake the data freely and publicly\\navailable. Data referring to Organelli\\net al. (2016a; https://doi.org/10.17882/47142)andBarbieuxetal.(2017;https://doi.org/10.17882/49388)arefreelyavailableonSEANOE.</dataset_id_with_context>  '"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29d7f58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labeled training data from: ./kaggle/input/make-data-count-finding-data-references\\train_labels.csv\n",
      "Training labels shape: (1028, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a0f79aca-eae4-4920-964a-c17318836aac",
       "rows": [
        [
         "0",
         "10.1002_2017jc013030",
         "https://doi.org/10.17882/49388",
         "Primary"
        ],
        [
         "1",
         "10.1002_anie.201916483",
         "Missing",
         "Missing"
        ],
        [
         "2",
         "10.1002_anie.202005531",
         "Missing",
         "Missing"
        ],
        [
         "3",
         "10.1002_anie.202007717",
         "Missing",
         "Missing"
        ],
        [
         "4",
         "10.1002_chem.201902131",
         "Missing",
         "Missing"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1002_2017jc013030</td>\n",
       "      <td>https://doi.org/10.17882/49388</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1002_anie.201916483</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1002_anie.202005531</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1002_anie.202007717</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1002_chem.201902131</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               article_id                      dataset_id     type\n",
       "0    10.1002_2017jc013030  https://doi.org/10.17882/49388  Primary\n",
       "1  10.1002_anie.201916483                         Missing  Missing\n",
       "2  10.1002_anie.202005531                         Missing  Missing\n",
       "3  10.1002_anie.202007717                         Missing  Missing\n",
       "4  10.1002_chem.201902131                         Missing  Missing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the labeled training data CSV file\n",
    "print(f\"Loading labeled training data from: {LABELED_TRAINING_DATA_CSV_PATH}\")\n",
    "train_labels_df = pd.read_csv(LABELED_TRAINING_DATA_CSV_PATH)\n",
    "\n",
    "print(f\"Training labels shape: {train_labels_df.shape}\")\n",
    "display(train_labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c538010a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped dataset ID counts:\n",
      "   dataset_id_trim  article_id\n",
      "52             htt         325\n",
      "29             Mis         309\n",
      "20             EPI          64\n",
      "47             SAM          41\n",
      "25             IPR          33\n",
      "11             CHE          29\n",
      "41             PRJ          26\n",
      "16             E-G          25\n",
      "19             ENS          21\n",
      "26             K02          20\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'dataset_id' by extracting the first 3 characters of the 'dataset_id' column\n",
    "train_labels_df['dataset_id_trim'] = train_labels_df['dataset_id'].str[:3]\n",
    "# Find the most frequent types of dataset_id's\n",
    "freq_dataset_id_df = train_labels_df.groupby('dataset_id_trim').count().reset_index()\n",
    "freq_dataset_id_df = freq_dataset_id_df[['dataset_id_trim', 'article_id']].sort_values(by='article_id', ascending=False)\n",
    "print(f\"Grouped dataset ID counts:\\n{freq_dataset_id_df.head(10)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2c96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_id_trim",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "be175d7b-7e40-480e-87b8-022e551c0d97",
       "rows": [
        [
         "372",
         "10.1128_JVI.01717-21",
         "EPI_ISL_291131",
         "Primary",
         "EPI"
        ],
        [
         "373",
         "10.1128_JVI.01717-21",
         "EPI_ISL_293286",
         "Primary",
         "EPI"
        ],
        [
         "374",
         "10.1128_JVI.01717-21",
         "EPI_ISL_293287",
         "Primary",
         "EPI"
        ],
        [
         "375",
         "10.1128_JVI.01717-21",
         "EPI_ISL_293288",
         "Primary",
         "EPI"
        ],
        [
         "376",
         "10.1128_JVI.01717-21",
         "EPI_ISL_293289",
         "Primary",
         "EPI"
        ],
        [
         "377",
         "10.1128_JVI.01717-21",
         "EPI_ISL_293290",
         "Primary",
         "EPI"
        ],
        [
         "378",
         "10.1128_JVI.01717-21",
         "EPI_ISL_293291",
         "Primary",
         "EPI"
        ],
        [
         "379",
         "10.1128_JVI.01717-21",
         "EPI_ISL_332358",
         "Primary",
         "EPI"
        ],
        [
         "380",
         "10.1128_JVI.01717-21",
         "EPI_ISL_332395",
         "Primary",
         "EPI"
        ],
        [
         "381",
         "10.1128_JVI.01717-21",
         "EPI_ISL_332396",
         "Primary",
         "EPI"
        ],
        [
         "382",
         "10.1128_JVI.01717-21",
         "EPI_ISL_332399",
         "Primary",
         "EPI"
        ],
        [
         "383",
         "10.1128_JVI.01717-21",
         "EPI_ISL_332401",
         "Primary",
         "EPI"
        ],
        [
         "384",
         "10.1128_JVI.01717-21",
         "EPI_ISL_376123",
         "Primary",
         "EPI"
        ],
        [
         "385",
         "10.1128_JVI.01717-21",
         "EPI_ISL_445001",
         "Primary",
         "EPI"
        ],
        [
         "386",
         "10.1128_JVI.01717-21",
         "EPI_ISL_445002",
         "Primary",
         "EPI"
        ],
        [
         "387",
         "10.1128_JVI.01717-21",
         "EPI_ISL_445051",
         "Primary",
         "EPI"
        ],
        [
         "388",
         "10.1128_JVI.01717-21",
         "EPI_ISL_445052",
         "Primary",
         "EPI"
        ],
        [
         "389",
         "10.1128_JVI.01717-21",
         "EPI_ISL_445089",
         "Primary",
         "EPI"
        ],
        [
         "390",
         "10.1128_JVI.01717-21",
         "EPI_ISL_445090",
         "Primary",
         "EPI"
        ],
        [
         "391",
         "10.1128_JVI.01717-21",
         "EPI_ISL_445091",
         "Primary",
         "EPI"
        ],
        [
         "392",
         "10.1128_JVI.01717-21",
         "EPI_ISL_445092",
         "Primary",
         "EPI"
        ],
        [
         "393",
         "10.1128_JVI.01717-21",
         "EPI_ISL_445093",
         "Primary",
         "EPI"
        ],
        [
         "830",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_10271777",
         "Secondary",
         "EPI"
        ],
        [
         "831",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_13295050",
         "Secondary",
         "EPI"
        ],
        [
         "832",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_1626969",
         "Secondary",
         "EPI"
        ],
        [
         "833",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_17371329",
         "Secondary",
         "EPI"
        ],
        [
         "834",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_2340570",
         "Secondary",
         "EPI"
        ],
        [
         "835",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_2340575",
         "Secondary",
         "EPI"
        ],
        [
         "836",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_2340581",
         "Secondary",
         "EPI"
        ],
        [
         "837",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_2340614",
         "Secondary",
         "EPI"
        ],
        [
         "838",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_2340615",
         "Secondary",
         "EPI"
        ],
        [
         "839",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_2340626",
         "Secondary",
         "EPI"
        ],
        [
         "840",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_2340662",
         "Secondary",
         "EPI"
        ],
        [
         "841",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_2365356",
         "Secondary",
         "EPI"
        ],
        [
         "842",
         "10.3389_fcimb.2024.1292467",
         "EPI_ISL_2402571",
         "Secondary",
         "EPI"
        ],
        [
         "900",
         "10.3390_v11060565",
         "EPI1018205",
         "Secondary",
         "EPI"
        ],
        [
         "901",
         "10.3390_v11060565",
         "EPI1018206",
         "Secondary",
         "EPI"
        ],
        [
         "902",
         "10.3390_v11060565",
         "EPI1018207",
         "Secondary",
         "EPI"
        ],
        [
         "903",
         "10.3390_v11060565",
         "EPI1018208",
         "Secondary",
         "EPI"
        ],
        [
         "904",
         "10.3390_v11060565",
         "EPI1018210",
         "Secondary",
         "EPI"
        ],
        [
         "905",
         "10.3390_v11060565",
         "EPI1018211",
         "Secondary",
         "EPI"
        ],
        [
         "906",
         "10.3390_v11060565",
         "EPI1019551",
         "Secondary",
         "EPI"
        ],
        [
         "907",
         "10.3390_v11060565",
         "EPI1019552",
         "Secondary",
         "EPI"
        ],
        [
         "908",
         "10.3390_v11060565",
         "EPI1019553",
         "Secondary",
         "EPI"
        ],
        [
         "909",
         "10.3390_v11060565",
         "EPI1019554",
         "Secondary",
         "EPI"
        ],
        [
         "910",
         "10.3390_v11060565",
         "EPI1019555",
         "Secondary",
         "EPI"
        ],
        [
         "911",
         "10.3390_v11060565",
         "EPI1019556",
         "Secondary",
         "EPI"
        ],
        [
         "912",
         "10.3390_v11060565",
         "EPI1019558",
         "Secondary",
         "EPI"
        ],
        [
         "913",
         "10.3390_v11060565",
         "EPI1104284",
         "Secondary",
         "EPI"
        ],
        [
         "914",
         "10.3390_v11060565",
         "EPI1104285",
         "Secondary",
         "EPI"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 64
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>type</th>\n",
       "      <th>dataset_id_trim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>10.1128_JVI.01717-21</td>\n",
       "      <td>EPI_ISL_291131</td>\n",
       "      <td>Primary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>10.1128_JVI.01717-21</td>\n",
       "      <td>EPI_ISL_293286</td>\n",
       "      <td>Primary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>10.1128_JVI.01717-21</td>\n",
       "      <td>EPI_ISL_293287</td>\n",
       "      <td>Primary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>10.1128_JVI.01717-21</td>\n",
       "      <td>EPI_ISL_293288</td>\n",
       "      <td>Primary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>10.1128_JVI.01717-21</td>\n",
       "      <td>EPI_ISL_293289</td>\n",
       "      <td>Primary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>10.3390_v11060565</td>\n",
       "      <td>EPI954554</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>10.3390_v11060565</td>\n",
       "      <td>EPI954555</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>10.3390_v11060565</td>\n",
       "      <td>EPI954556</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>10.3390_v11060565</td>\n",
       "      <td>EPI954557</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>10.3390_v11060565</td>\n",
       "      <td>EPI954559</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>EPI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               article_id      dataset_id       type dataset_id_trim\n",
       "372  10.1128_JVI.01717-21  EPI_ISL_291131    Primary             EPI\n",
       "373  10.1128_JVI.01717-21  EPI_ISL_293286    Primary             EPI\n",
       "374  10.1128_JVI.01717-21  EPI_ISL_293287    Primary             EPI\n",
       "375  10.1128_JVI.01717-21  EPI_ISL_293288    Primary             EPI\n",
       "376  10.1128_JVI.01717-21  EPI_ISL_293289    Primary             EPI\n",
       "..                    ...             ...        ...             ...\n",
       "924     10.3390_v11060565       EPI954554  Secondary             EPI\n",
       "925     10.3390_v11060565       EPI954555  Secondary             EPI\n",
       "926     10.3390_v11060565       EPI954556  Secondary             EPI\n",
       "927     10.3390_v11060565       EPI954557  Secondary             EPI\n",
       "928     10.3390_v11060565       EPI954559  Secondary             EPI\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df[train_labels_df['dataset_id_trim'] == 'EPI'].sample(3)  # Display the first 10 rows where dataset_id_trim is 'htt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "560a47e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example grouped training data for article_id '10.1002_2017jc013030': [{'dataset_id': 'https://doi.org/10.17882/49388', 'type': 'Primary'}]\n"
     ]
    }
   ],
   "source": [
    "# Group training data by article_id to get all datasets for each article\n",
    "# This creates a dictionary where keys are article_ids and values are lists of dataset dicts\n",
    "grouped_training_data = {}\n",
    "for article_id, group_df in train_labels_df.groupby('article_id'):\n",
    "    grouped_training_data[article_id] = group_df[['dataset_id', 'type']].to_dict('records')\n",
    "\n",
    "# Example usage of grouped_training_data\n",
    "print(f\"Example grouped training data for article_id '10.1002_2017jc013030': {grouped_training_data['10.1002_2017jc013030']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "34f61a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files paths shape: (494, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "xml_file_path",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "dataset_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_info",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "fb8a983d-79cb-4664-8d7a-a98a89da05f2",
       "rows": [
        [
         "218",
         "10.1186_s11658-018-0120-2",
         "./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s11658-018-0120-2.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\train\\XML\\10.1186_s11658-018-0120-2.xml",
         "train",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "61",
         "10.1029_2020jf005675",
         "./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1029_2020jf005675.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\train\\XML\\10.1029_2020jf005675.xml",
         "train",
         "[{'dataset_id': 'https://doi.org/10.5066/p9bu8faq', 'type': 'Primary'}]"
        ],
        [
         "404",
         "10.1590_0034-737x201966050002",
         "./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_0034-737x201966050002.pdf",
         null,
         "train",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>pdf_file_path</th>\n",
       "      <th>xml_file_path</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>dataset_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>10.1186_s11658-018-0120-2</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10.1029_2020jf005675</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5066/p9bu8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>10.1590_0034-737x201966050002</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        article_id  \\\n",
       "218      10.1186_s11658-018-0120-2   \n",
       "61            10.1029_2020jf005675   \n",
       "404  10.1590_0034-737x201966050002   \n",
       "\n",
       "                                         pdf_file_path  \\\n",
       "218  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "61   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "404  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "\n",
       "                                         xml_file_path dataset_type  \\\n",
       "218  ./kaggle/input/make-data-count-finding-data-re...        train   \n",
       "61   ./kaggle/input/make-data-count-finding-data-re...        train   \n",
       "404                                                NaN        train   \n",
       "\n",
       "                                          dataset_info  \n",
       "218     [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "61   [{'dataset_id': 'https://doi.org/10.5066/p9bu8...  \n",
       "404     [{'dataset_id': 'Missing', 'type': 'Missing'}]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test files paths shape: (30, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "xml_file_path",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "dataset_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_info",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "bfb9674f-2f5c-447d-92c6-dba554de88a0",
       "rows": [
        [
         "29",
         "10.1007_jhep07(2018)134",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1007_jhep07(2018)134.pdf",
         null,
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "0",
         "10.1002_2017jc013030",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_2017jc013030.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_2017jc013030.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.17882/49388', 'type': 'Primary'}]"
        ],
        [
         "7",
         "10.1002_chem.202001412",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.202001412.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_chem.202001412.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>pdf_file_path</th>\n",
       "      <th>xml_file_path</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>dataset_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.1007_jhep07(2018)134</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1002_2017jc013030</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.17882/4938...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1002_chem.202001412</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article_id  \\\n",
       "29  10.1007_jhep07(2018)134   \n",
       "0      10.1002_2017jc013030   \n",
       "7    10.1002_chem.202001412   \n",
       "\n",
       "                                        pdf_file_path  \\\n",
       "29  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "0   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "7   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "\n",
       "                                        xml_file_path dataset_type  \\\n",
       "29                                                NaN         test   \n",
       "0   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "7   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "\n",
       "                                         dataset_info  \n",
       "29     [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "0   [{'dataset_id': 'https://doi.org/10.17882/4938...  \n",
       "7      [{'dataset_id': 'Missing', 'type': 'Missing'}]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load file paths for training and testing datasets\n",
    "train_file_paths_df = load_file_paths(ARTICLE_TRAIN_DIR)\n",
    "test_file_paths_df = load_file_paths(ARTICLE_TEST_DIR)\n",
    "\n",
    "# Remove rows in train_file_paths_df that have a corresponding article_id in test_file_paths_df\n",
    "train_file_paths_df = train_file_paths_df[~train_file_paths_df['article_id'].isin(test_file_paths_df['article_id'])]\n",
    "\n",
    "# Merge the file paths with the grouped_training_data\n",
    "train_file_paths_df['dataset_info'] = train_file_paths_df['article_id'].map(grouped_training_data)\n",
    "test_file_paths_df['dataset_info'] = test_file_paths_df['article_id'].map(grouped_training_data)\n",
    "\n",
    "print(f\"Train files paths shape: {train_file_paths_df.shape}\")\n",
    "display(train_file_paths_df.sample(3))\n",
    "print(f\"Test files paths shape: {test_file_paths_df.shape}\")\n",
    "display(test_file_paths_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "2640c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- QwenModelEval Class ---\n",
    "# kagglehub.model_download(\"qwen-lm/qwen-3/transformers/0.6b\")\n",
    "#max_new_tokens=32768\n",
    "class QwenModelEval:\n",
    "    def __init__(self, model_name, sys_prompt, enable_thinking=True, max_new_tokens=1024):\n",
    "        print(f\"Loading Qwen model and tokenizer from: {model_name}\")\n",
    "        self.model_name = model_name\n",
    "        self.sys_prompt = sys_prompt\n",
    "        self.enable_thinking = enable_thinking  # Enable or disable thinking mode\n",
    "        self.max_new_tokens = max_new_tokens  # Set the maximum number of new tokens to generate\n",
    "        # Load the tokenizer and model\n",
    "        # Using trust_remote_code=True to allow custom model code execution\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"auto\", trust_remote_code=True)\n",
    "        self.model.eval() # Set the model to evaluation mode here.\n",
    "\n",
    "    def generate_response(self, user_input):  \n",
    "        inputs = self._get_inputs(user_input)\n",
    "        # Disable gradient calculation during inference\n",
    "        # Generate the response using the model\n",
    "        with torch.no_grad(): \n",
    "            generated_ids = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=self.max_new_tokens,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                eos_token_id=self.tokenizer.convert_tokens_to_ids(\"<|im_end|>\"),\n",
    "                # do_sample=False, # Use greedy decoding (fastest)\n",
    "                # num_beams=1,     # Do not use beam search (fastest)\n",
    "                # temperature=0.0, # Make output deterministic (if do_sample=False, this has no effect)                \n",
    "                temperature=0.6 if self.enable_thinking else 0.7,\n",
    "                top_p=0.95 if self.enable_thinking else 0.8,\n",
    "                top_k=20,\n",
    "                min_p=0\n",
    "            )\n",
    "        # Parse the response and thinking content\n",
    "        return self._parse_response(inputs, generated_ids)\n",
    "\n",
    "    def _get_inputs(self, user_input):\n",
    "        \"\"\"Prepare the input for the model based on user input.\"\"\"\n",
    "        # Trim the user input to a maximum length for better performance\n",
    "        user_input = user_input[:4096]  # Limit input length to 4096 characters\n",
    "        print(f\"Preparing input with length: {len(user_input)}\")\n",
    "        # Create the messages for the chat template\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=self.enable_thinking\n",
    "        )\n",
    "        return self.tokenizer(text, return_tensors=\"pt\").to(self.model.device)\n",
    "    \n",
    "    def _parse_response(self, inputs, generated_ids):\n",
    "        print(\"Parsing response from generated IDs...\")\n",
    "        # Extract the output IDs from the generated IDs\n",
    "        output_ids = generated_ids[0][len(inputs.input_ids[0]):].tolist()\n",
    "        try:\n",
    "            index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "        except ValueError:\n",
    "            index = 0\n",
    "\n",
    "        thinking_content = self.tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "        response = self.tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "        return response, thinking_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "74e5a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the one-shot reasoning, task, and example prompt\n",
    "# This prompt is designed to guide the model through a structured reasoning process\n",
    "\n",
    "# reason_prompt =  '''\n",
    "# You are an advanced AI reasoning assistant tasked with delivering a comprehensive analysis of a specific problem or question.  Your goal is to outline your reasoning process in a structured and transparent manner, with each step reflecting a thorough examination of the issue at hand, culminating in a well-reasoned conclusion.\n",
    "\n",
    "# ### Key Instructions:\n",
    "# 1.  Conduct **at least 5 distinct reasoning steps**, each building on the previous one.\n",
    "# 2.  **Acknowledge the limitations** inherent to AI, specifically what you can accurately assess and what you may struggle with.\n",
    "# 3.  **Adopt multiple reasoning frameworks** to resolve the problem or derive conclusions, such as:\n",
    "# - **Deductive reasoning** (drawing specific conclusions from general principles)\n",
    "# - **Inductive reasoning** (deriving broader generalizations from specific observations)\n",
    "# - **Abductive reasoning** (choosing the best possible explanation for the given evidence)\n",
    "# - **Analogical reasoning** (solving problems through comparisons and analogies)\n",
    "# 4.  **Critically analyze your reasoning** to identify potential flaws, biases, or gaps in logic.\n",
    "# 5.  When reviewing, apply a **fundamentally different perspective or approach** to enhance your analysis.\n",
    "# 6.  **Employ at least 2 distinct reasoning methods** to derive or verify the accuracy of your conclusions.\n",
    "# 7.  **Incorporate relevant domain knowledge** and **best practices** where applicable, ensuring your reasoning aligns with established standards.\n",
    "# 8.  **Quantify certainty levels** for each step and your final conclusion, where applicable.\n",
    "# 9.  Consider potential **edge cases or exceptions** that could impact the outcome of your reasoning.\n",
    "# 10.  Provide **clear justifications** for dismissing alternative hypotheses or solutions that arise during your analysis.\n",
    "# '''\n",
    "\n",
    "reason_prompt =  '''\n",
    "You are an advanced AI research assistant that is skilled in identifying and classifying datasets used within academic research papers.\n",
    "Be as accurate as possible but don't over think it.\n",
    "'''\n",
    "\n",
    "task_prompt = '''\n",
    "You are given an article_id and the associated text of an academic research paper.\n",
    "Within the text of the paper, you are given an abstract and a list of potential_dataset_ids that contains dataset_ids and their associated context within the paper.\n",
    "You have 3 tasks:\n",
    "\n",
    "1. Your first task is to identify all citations of datasets used in the research for this article. An article may cite zero or many datasets.\n",
    "Datasets in an article can be cited within the context using various terms such as \"data release\", \"data availability\", \"dataset\", \"database\", \"repository\", \"data source\", \"data access\", \"data archive\".\n",
    "Each dataset has a unique, persistent identifier to represent it called a dataset_id. If you find more than one citation of the same dataset_id, only process the first one.\n",
    "\n",
    "There are 2 ways to identify a dataset_id:\n",
    "The first way to identify a dataset_id is via a Digital Object Identifier (DOI). DOIs are used for all papers and some datasets. We want to identify DOIs that are used as dataset_id's, not the DOI of the paper itself or any other papers.\n",
    "They take the following form: https://doi.org/[prefix]/[suffix]. The prefix always starts with \"10.\" and is followed by a 4 or 5 digit number. The suffix can contain letters, numbers, and special characters.\n",
    "Examples:\n",
    "https://doi.org/10.17882/49388\n",
    "https://doi.org/10.1371/journal.pone.0303785\n",
    "https://doi.org/10.5061/dryad.r6nq870\n",
    "https://doi.org/10.7937/tcia.2020.6c7y-gq39\n",
    "https://doi.org/10.5281/zenodo.8338991\n",
    "\n",
    "The second way to identify a dataset_id is via an Accession ID. Accession ID's vary in form by individual data repository where the data live. \n",
    "Examples:\n",
    "\"EPI_ISL_10271777\" (EPI dataset)\n",
    "\"IPR000264\" (InterPro dataset)\n",
    "\"SAMN07159041\" (NCBI Sequence Read Archive dataset)\n",
    "\"CHEMBL1782574\" (ChEMBL dataset)\n",
    "\"PRJNA287300\" (NCBI BioProject dataset)\n",
    "\"E-GEOD-19722\" (ArrayExpress dataset)\n",
    "\"E-MEXP-568\" (ArrayExpress dataset)\n",
    "\"GSE12345\" (Gene Expression Omnibus dataset)\n",
    "“PDB 1Y2T” (Protein Data Bank dataset)\n",
    "\"EMPIAR-10005\" (Electron Microscopy Public Image Archive dataset)\n",
    "\"CAB000001\" (CAB Direct dataset)\n",
    "\"CVCL_1234\" (Cellosaurus dataset)\n",
    "\n",
    "\n",
    "2. Your second task is to classify the type of each dataset_id that you find as \"Primary\" or \"Secondary\" as it is used within the context of the paper.\n",
    "Primary - raw or processed data generated as part of this paper, specifically for this study\n",
    "Secondary - raw or processed data derived or reused from existing records or published data\n",
    "\n",
    "3. Your third task is to return your results in a JSON format.\n",
    "If an article does not refer to any dataset_id's, return a single JSON object with the following structure:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"dataset_id\": \"Missing\",\n",
    "        \"type\": \"Missing\"\n",
    "    }\n",
    "]\n",
    "If an article refers to one or more dataset_id's, you need to classify the type of each dataset as \"Primary\" or \"Secondary\" and\n",
    "return every dataset found in a JSON array of objects, where each object has the following structure:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"dataset_id\": dataset_id here,\n",
    "        \"type\": type here\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "'''\n",
    "\n",
    "SYS_PROMPT = reason_prompt + task_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a43a2780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "xml_file_path",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "dataset_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_info",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "08c2451a-0774-4674-8339-871085f8d6c1",
       "rows": [
        [
         "52",
         "10.1017_rdc.2022.19",
         "./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1017_rdc.2022.19.pdf",
         null,
         "train",
         "[{'dataset_id': 'https://doi.org/10.11588/data/10100', 'type': 'Secondary'}]"
        ],
        [
         "53",
         "10.1017_s0007123423000601",
         "./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1017_s0007123423000601.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\train\\XML\\10.1017_s0007123423000601.xml",
         "train",
         "[{'dataset_id': 'https://doi.org/10.7910/dvn/fwckse', 'type': 'Primary'}]"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>pdf_file_path</th>\n",
       "      <th>xml_file_path</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>dataset_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10.1017_rdc.2022.19</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.11588/data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10.1017_s0007123423000601</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.7910/dvn/f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   article_id  \\\n",
       "52        10.1017_rdc.2022.19   \n",
       "53  10.1017_s0007123423000601   \n",
       "\n",
       "                                        pdf_file_path  \\\n",
       "52  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "53  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "\n",
       "                                        xml_file_path dataset_type  \\\n",
       "52                                                NaN        train   \n",
       "53  ./kaggle/input/make-data-count-finding-data-re...        train   \n",
       "\n",
       "                                         dataset_info  \n",
       "52  [{'dataset_id': 'https://doi.org/10.11588/data...  \n",
       "53  [{'dataset_id': 'https://doi.org/10.7910/dvn/f...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_file_paths_df['text'] = train_file_paths_df['pdf_file_path'].apply(load_article_text)\n",
    "# test_file_paths_df['text'] = test_file_paths_df['pdf_file_path'].apply(load_article_text)\n",
    "\n",
    "#Create a new df from train_file_paths_df where the string representation of dataset_info does not contain 'Missing'.\n",
    "train_file_paths_df_2 = train_file_paths_df[~train_file_paths_df['dataset_info'].astype(str).str.contains('Missing')]\n",
    "train_file_paths_df_3 = train_file_paths_df_2[train_file_paths_df_2['article_id'].astype(str).str.contains('10.1017_')]\n",
    "train_file_paths_df_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "f8a8a117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen model and tokenizer from: C:\\Users\\jim\\.cache\\kagglehub\\models\\qwen-lm\\qwen-3\\transformers\\0.6b\\1\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the QwenModelEval class with the model path and system prompt\n",
    "inference_model = QwenModelEval(QWEN_BASE_MODEL_PATH, sys_prompt=SYS_PROMPT, enable_thinking=True, max_new_tokens=1576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "749ca3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_articles(file_paths_df: pd.DataFrame, model) -> pd.DataFrame:\n",
    "    results = []\n",
    "    for i, row in file_paths_df.iterrows():\n",
    "        article_id = row['article_id']\n",
    "        pdf_file_path = row['pdf_file_path']\n",
    "        xml_file_path = row['xml_file_path']\n",
    "\n",
    "        print(f\"Processing article {i}/{len(file_paths_df)}: {article_id}\")\n",
    "\n",
    "        # Load the text content from the PDF or XML file\n",
    "        text_content = load_article_text(pdf_file_path) if pdf_file_path else load_article_text(xml_file_path)\n",
    "\n",
    "        # Prepare the user input for the model\n",
    "        user_input = f\"Article ID: {article_id}\\nText Content: {text_content}\\n\"\n",
    "\n",
    "        # Generate response from the model\n",
    "        response, thinking_content = model.generate_response(user_input)\n",
    "\n",
    "        results.append({\n",
    "            'article_id': article_id,\n",
    "            'llm_input': user_input,\n",
    "            'llm_response': response,\n",
    "            'llm_thinking_content': thinking_content\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(by=[\"article_id\"]).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "4d2524bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article 52/2: 10.1017_rdc.2022.19\n",
      "Total blocks with data related dataset IDs found: 1\n",
      "Extracted text from ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1017_rdc.2022.19.pdf. Length: 1934 characters\n",
      "Preparing input with length: 1982\n",
      "Parsing response from generated IDs...\n",
      "Processing article 53/2: 10.1017_s0007123423000601\n",
      "Total blocks with data related dataset IDs found: 1\n",
      "Extracted text from ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1017_s0007123423000601.pdf. Length: 1248 characters\n",
      "Preparing input with length: 1302\n",
      "Parsing response from generated IDs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_response",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_thinking_content",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "30ca21fa-452f-4cef-90de-0fa7acd343a4",
       "rows": [
        [
         "0",
         "10.1017_rdc.2022.19",
         "Article ID: 10.1017_rdc.2022.19\nText Content: ABSTRACT.\nIn the frame of the IAEA-CRP (Coordinated Research Projects): Enhancing Nuclear Analytical Techniques to Meet the Needs of Forensic Sciences, an intercomparison exercise was organized between three AMS laboratories.\nAim of the program is to promote the use of nuclear and accelerator-based techniques in routine forensics practice.\nIn this view, one of the key points is the assessment of the precision and accuracy levels achievable on material of forensic interest.\nWe review the general structure and status of the project, with emphasis on results obtained in the analysis of wines of different grape varieties and grounded coffee beans from different locations such as Brazil, Spain, and Italy.\nThe three laboratories processed the samples according to different chemical protocols and performed the 14C measurements using different systems: MICADAS in Zurich and Debrecen and a HVEE 4130HC 3 MV Tandetron in Lecce.\nWithin the quoted uncertainty, the results showed good reproducibility, indicating that uncertainty level of the order of 0.3% are achieved by AMS on a single sample while multiple sample analyses results in precision down to 0.1–0.2%.\nThe measured 14C concentrations on coffee and wine samples resulted to be consistent with atmospheric 14C levels in the growing years. .\n potential_dataset_ids: [{\"dataset_ids\": ['https://doi.org/10.11588/data/10100'], context: \" L, Fedi M, Friedrich R, Maspero F, Sava T. 2019.\nradiocarbon dating and the protection of cultural heritage.\nRadiocarbon 61(5):1133–1134. \nHammer S, Levin I. 2017. \nMonthly mean atmospheric D14CO2 at Jungfraujoch and Schauinsland from 1986 to 2016.\nhttps://doi.org/10.11588/data/10100 heiDATA: Heidelberg Research Data Repository [Distributor] V2 [Version]. \nHandlos P, Svetlik I, Horáčková L, Fejgl M, Kotik L, Brychová V, Megisova N, Marecová K. 2018. \nBomb peak: radiocarbon dating of skeletal remains in routine forensic medical p\"},]\n",
         "```json\n[\n    {\n        \"dataset_id\": \"https://doi.org/10.11588/data/10100\",\n        \"type\": \"Primary\"\n    },\n    {\n        \"dataset_id\": \"https://doi.org/10.11588/data/10100\",\n        \"type\": \"Secondary\"\n    }\n]\n```",
         "<think>\nOkay, let's tackle this problem step by step. The user provided an article with an ID and a text abstract. They also have a list of potential_dataset_ids and a context where the datasets are mentioned. My job is to identify citations of datasets, classify their types, and return the results in JSON.\n\nFirst, I need to look through the text of the paper to see where dataset IDs are mentioned. The abstract mentions three laboratories, their analysis methods, and results. The potential_dataset_ids include a few entries, but I need to check if they correspond to the datasets used in the paper.\n\nLooking at the first dataset ID: https://doi.org/10.11588/data/10100. The context says it's from the \"Heidelberg Research Data Repository\" in the context of L, Fedi M, Friedrich R, Maspero F, Sava T. 2019. The paper is about radiocarbon dating and the protection of cultural heritage. The DOI seems to be for a dataset related to radiocarbon dating. \n\nThen there's another entry: https://doi.org/10.11588/data/10100 heiDATA: ... which also points to the same repository. The context here is about the study's methods and data collection. \n\nI need to check if these DOIs are specific to the datasets used in the paper. The first dataset is about radiocarbon dating, which is a technique used in the study. The second dataset is part of the repository, which might be a database or archive where the data are stored. \n\nNow, the task is to classify these datasets as Primary or Secondary. Primary would be raw data generated in the study, while Secondary would be data reused from existing sources. Since the study involved processing samples using specific protocols, and the data were collected from those protocols, the first dataset seems to be a raw dataset used for analysis. The second dataset might be a database or archive, which could be secondary if it's data from another study or dataset. \n\nBut wait, the first dataset ID is mentioned in the context of the study's methods. The first dataset is likely the raw data used in the analysis. The second dataset might be a secondary dataset since it's part of the repository. \n\nTherefore, the JSON should include both dataset IDs with their respective types. The first dataset is Primary, and the second is Secondary. The user needs to return them in a JSON array. Let me make sure there are no other dataset IDs to consider. The potential_dataset_ids list has two entries, both pointing to the same repository, so they are the same dataset. So only those two entries need to be considered. \n\nWait, but the user's potential_dataset_ids list includes two entries, but the text mentions both. So I need to process both. The first dataset is from the first entry, and the second is from the heiDATA entry. Both are the same dataset, so the first one is Primary, and the second is Secondary. \n\nPutting it all together, the JSON should have two entries with their respective types.\n</think>"
        ],
        [
         "1",
         "10.1017_s0007123423000601",
         "Article ID: 10.1017_s0007123423000601\nText Content: Abstract Like much of the European centre-left, Britain’s Labour Party has struggled to appeal to its former core working class support base in recent years.\nHowever, this is largely a failure to connect with the ‘white working class’ (WWC) specifically, whereas support among ethnic minorities remains robust.\nWe hypothesise that Labour could be experiencing a ‘trade-off’, whereby efforts to cater to minorities harm its perceived ability to represent WWC interests.\nWe test this thesis by examining whether WWC voters are more likely to view minority and working class representation in zero-sum terms and shun Labour when they associate the party with minority interests.\nWe show that the WWC are somewhat less likely to view working class and ethnic minority representation as strongly correlated, and Labour’s perceived ability to represent minorities is negatively associated with WWC support.\nThis is not (primarily) about ethnocentrism.\nInstead, we suggest that ‘relative political deprivation’ is crucial. .\n potential_dataset_ids: [{\"dataset_ids\": ['https://doi.org/10.7910/DVN/FWCKSE'], context: \"Data availability statement.\nReplication data for this article can be found in Harvard Dataverse at: https://doi.org/10.7910/DVN/FWCKSE \"},]\n",
         "```json\n[\n    {\n        \"dataset_id\": \"https://doi.org/10.7910/DVN/FWCKSE\",\n        \"type\": \"Primary\"\n    }\n]\n```",
         "<think>\nOkay, let's start by looking at the article ID provided: 10.1017_s0007123423000601. The text content is about the Labour Party's struggles with its working class support base and the concept of a trade-off. The abstract mentions that the study examines how WWC voters perceive minority and working class representation and their likelihood to shun Labour when associated with minority interests.\n\nNow, the potential_dataset_ids given are a list with one entry: https://doi.org/10.7910/DVN/FWCKSE, which is a Digital Object Identifier (DOI). The context here says it's a \"data availability statement\" and mentions replication data in Harvard Dataverse. \n\nThe first task is to identify all citations of datasets. Since this is a DOI, it's likely the dataset_id. The second task is to classify the type as Primary or Secondary. The abstract doesn't mention any datasets in the context, so maybe both are missing. But since the potential_dataset_ids include this DOI, we should process it. \n\nWait, the user's instruction says to classify each dataset_id as Primary or Secondary. If there's only one dataset_id here, and the context is about data availability, perhaps it's considered Primary data because it's used for replication. However, the abstract doesn't explicitly state it's a dataset, just that it's a data availability statement. \n\nSo, the JSON should include the dataset_id and type. Since there's only one dataset_id here, even though the abstract doesn't mention it as a dataset, the potential_dataset_ids include it. Therefore, the JSON would have the dataset_id as the provided DOI and type as Primary, assuming it's replication data.\n</think>"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>llm_input</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>llm_thinking_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1017_rdc.2022.19</td>\n",
       "      <td>Article ID: 10.1017_rdc.2022.19\\nText Content:...</td>\n",
       "      <td>```json\\n[\\n    {\\n        \"dataset_id\": \"http...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's tackle this problem step ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1017_s0007123423000601</td>\n",
       "      <td>Article ID: 10.1017_s0007123423000601\\nText Co...</td>\n",
       "      <td>```json\\n[\\n    {\\n        \"dataset_id\": \"http...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's start by looking at the a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  article_id  \\\n",
       "0        10.1017_rdc.2022.19   \n",
       "1  10.1017_s0007123423000601   \n",
       "\n",
       "                                           llm_input  \\\n",
       "0  Article ID: 10.1017_rdc.2022.19\\nText Content:...   \n",
       "1  Article ID: 10.1017_s0007123423000601\\nText Co...   \n",
       "\n",
       "                                        llm_response  \\\n",
       "0  ```json\\n[\\n    {\\n        \"dataset_id\": \"http...   \n",
       "1  ```json\\n[\\n    {\\n        \"dataset_id\": \"http...   \n",
       "\n",
       "                                llm_thinking_content  \n",
       "0  <think>\\nOkay, let's tackle this problem step ...  \n",
       "1  <think>\\nOkay, let's start by looking at the a...  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_articles_df = process_articles(train_file_paths_df_3, inference_model)\n",
    "processed_articles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "e9bb547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed_articles_df to CSV\n",
    "processed_articles_df.to_csv(\"processed_articles.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e4ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article 1/2: 10.1017_rdc.2022.19\n",
      "Total blocks with data related dataset IDs found: 1\n",
      "Extracted text from ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1017_rdc.2022.19.pdf. Length: 1934 characters\n",
      "Preparing input with length: 1982\n",
      "Generating response for user input:\n",
      "Parsing response from generated IDs...\n",
      "Response for article 10.1017_rdc.2022.19:\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"dataset_id\": \"https://doi.org/10.11588/data/10100\",\n",
      "        \"type\": \"Primary\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Thinking Content:\n",
      "<think>\n",
      "Okay, let's tackle this step by step. The user provided an article ID and a text content, along with a list of potential dataset_ids. My job is to identify all citations of datasets used in the research for this article and classify each dataset as Primary or Secondary.\n",
      "\n",
      "First, I need to look through the dataset_ids provided. The first entry is \"https://doi.org/10.11588/data/10100\". The context mentions \"radiocarbon dating and the protection of cultural heritage\" by L, Fedi M, etc. That seems like a standard radiocarbon dating paper. The DOI here is for a dataset, which is a bit confusing because radiocarbon dating is a method, not a dataset. Wait, maybe the dataset_id is for the paper's data, but the DOI here is for the paper itself. Hmm, maybe the dataset_id is the DOI of the dataset, and the context refers to the dataset's content. So in this case, the dataset_id is the DOI, and the context is about the data used. So this would be a Primary dataset because it's data used in the study.\n",
      "\n",
      "Next, the second dataset_id is \"https://doi.org/10.1017_rdc.2022.19\". The context here is the article's text, which is the abstract. The article is about an intercomparison exercise between three laboratories. The dataset_ids in the text are not directly related to the study's data. So maybe this is a citation to another dataset, but since the text is the abstract, perhaps it's not a dataset ID but a citation. Wait, the user provided the potential_dataset_ids, so I need to check if these IDs actually exist in the text. The first potential_dataset_id's context mentions a paper with a DOI and a repository. The second one's context is the article's text. \n",
      "\n",
      "So the first dataset_id is a DOI for a paper, which is a dataset. The second one is from the article's text, but the user's task is to find dataset IDs in the text. Since the text is the abstract, perhaps there are no dataset IDs in the text. Therefore, the only dataset found here is the first one. \n",
      "\n",
      "Wait, the user's text content starts with the abstract. The potential_dataset_ids list includes entries that mention radiocarbon dating papers. So the first dataset_id is for a radiocarbon dating paper, which is a dataset. The second one is from the article's text, which might not be a dataset ID but a citation. Therefore, only the first dataset_id is a dataset, and the second is a citation. \n",
      "\n",
      "So the classification would be Primary for the first dataset_id, as it's data used in the study. The second dataset_id is not a dataset ID but part of the text, so it's not considered. Therefore, the JSON should have the dataset_id from the first entry and type Primary.\n",
      "</think>\n",
      "\n",
      "Processing article 2/2: 10.1017_s0007123423000601\n",
      "Total blocks with data related dataset IDs found: 1\n",
      "Extracted text from ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1017_s0007123423000601.pdf. Length: 1248 characters\n",
      "Preparing input with length: 1302\n",
      "Generating response for user input:\n",
      "Parsing response from generated IDs...\n",
      "Response for article 10.1017_s0007123423000601:\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"dataset_id\": \"https://doi.org/10.7910/DVN/FWCKSE\",\n",
      "        \"type\": \"Primary\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Thinking Content:\n",
      "<think>\n",
      "Okay, let's see. The user provided an article ID and a text content, and they want me to identify dataset IDs and classify them as primary or secondary. The article mentions data availability in the context of a Harvard Dataverse. \n",
      "\n",
      "First, I need to check if there are any dataset IDs in the potential_dataset_ids list. The example given includes a dataset_id from the Harvard Dataverse. The URL is https://doi.org/10.7910/DVN/FWCKSE. \n",
      "\n",
      "Looking at the first task, how to identify dataset IDs. The first way is using DOIs, which start with 10. followed by a number. The second way is Accession IDs, like EPI_ISL_10271777. The example here uses a DOI, so that's the dataset_id. \n",
      "\n",
      "So the dataset_id here is the one provided. Now, the second task is to classify as primary or secondary. The article mentions \"replication data for this article\" which is part of the dataset. Since the data is available for replication, it's likely primary data. \n",
      "\n",
      "Wait, but the original text doesn't mention any datasets in the abstract. The only data mentioned is the Harvard Dataverse. So the dataset_id here is the one from the Dataverse. \n",
      "\n",
      "Therefore, the classification should be primary because it's the data used for replication. The JSON structure needs to have the dataset_id and type. Since there's only one dataset, the JSON should include that. \n",
      "\n",
      "I need to make sure there are no other dataset IDs in the potential_dataset_ids. The list only has this one. So the final JSON should have the dataset_id and type as primary.\n",
      "</think>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "# Iterate through the training file paths DataFrame\n",
    "# For each article, load the text content and prepare the user input for the model\n",
    "for _, row in train_file_paths_df_3.iterrows():\n",
    "    article_id = row['article_id']\n",
    "    pdf_file_path = row['pdf_file_path']\n",
    "    xml_file_path = row['xml_file_path']\n",
    "    dataset_info = row['dataset_info']\n",
    "\n",
    "    if i < 2:  # Limit to first 2 articles for demonstration\n",
    "        i += 1\n",
    "        print(f\"Processing article {i}/{len(train_file_paths_df_3)}: {article_id}\")\n",
    "\n",
    "        # Load the text content from the PDF or XML file\n",
    "        text_content = load_article_text(pdf_file_path) if pdf_file_path else load_article_text(xml_file_path)\n",
    "\n",
    "        # Prepare the user input for the model\n",
    "        user_input = f\"Article ID: {article_id}\\nText Content: {text_content}\\n\"\n",
    "\n",
    "        # Initialize the model and tokenizer if not already done\n",
    "        if inference_model is None:\n",
    "            inference_model = QwenModelEval(QWEN_BASE_MODEL_PATH, sys_prompt=SYS_PROMPT)\n",
    "\n",
    "        # Generate response from the model\n",
    "        response, thinking_content = inference_model.generate_response(user_input)\n",
    "        \n",
    "        print(f\"Response for article {article_id}:\\n{response}\\nThinking Content:\\n{thinking_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "13ab8eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "xml_file_path",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "dataset_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_info",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "fab83318-f39b-4ca6-a678-92b0151a79fb",
       "rows": [
        [
         "0",
         "10.1002_2017jc013030",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_2017jc013030.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_2017jc013030.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.17882/49388', 'type': 'Primary'}]"
        ],
        [
         "1",
         "10.1002_anie.201916483",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_anie.201916483.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_anie.201916483.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "2",
         "10.1002_anie.202005531",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_anie.202005531.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_anie.202005531.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "3",
         "10.1002_anie.202007717",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_anie.202007717.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_anie.202007717.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "4",
         "10.1002_chem.201902131",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.201902131.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_chem.201902131.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "5",
         "10.1002_chem.201903120",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.201903120.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_chem.201903120.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "6",
         "10.1002_chem.202000235",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.202000235.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_chem.202000235.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "7",
         "10.1002_chem.202001412",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.202001412.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_chem.202001412.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "8",
         "10.1002_chem.202001668",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.202001668.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_chem.202001668.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "9",
         "10.1002_chem.202003167",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.202003167.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_chem.202003167.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "10",
         "10.1002_cssc.202201821",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_cssc.202201821.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_cssc.202201821.xml",
         "test",
         null
        ],
        [
         "11",
         "10.1002_ece3.3985",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.3985.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.3985.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "12",
         "10.1002_ece3.4466",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.4466.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.4466.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.5061/dryad.r6nq870', 'type': 'Primary'}]"
        ],
        [
         "13",
         "10.1002_ece3.5260",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.5260.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.5260.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.5061/dryad.2f62927', 'type': 'Primary'}]"
        ],
        [
         "14",
         "10.1002_ece3.5395",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.5395.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.5395.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "15",
         "10.1002_ece3.6144",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.6144.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.6144.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.5061/dryad.zw3r22854', 'type': 'Primary'}]"
        ],
        [
         "16",
         "10.1002_ece3.6303",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.6303.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.6303.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.5061/dryad.37pvmcvgb', 'type': 'Primary'}]"
        ],
        [
         "17",
         "10.1002_ece3.6784",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.6784.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.6784.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "18",
         "10.1002_ece3.961",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.961.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.961.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "19",
         "10.1002_ece3.9627",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.9627.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.9627.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.5061/dryad.b8gtht7h3', 'type': 'Primary'}]"
        ],
        [
         "20",
         "10.1002_ecs2.1280",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ecs2.1280.pdf",
         null,
         "test",
         "[{'dataset_id': 'https://doi.org/10.5061/dryad.p3fg9', 'type': 'Primary'}]"
        ],
        [
         "21",
         "10.1002_ecs2.4619",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ecs2.4619.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ecs2.4619.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.25349/d9qw5x', 'type': 'Primary'}]"
        ],
        [
         "22",
         "10.1002_ejic.201900904",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ejic.201900904.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ejic.201900904.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "23",
         "10.1002_ejoc.202000139",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ejoc.202000139.pdf",
         null,
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "24",
         "10.1002_ejoc.202000916",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ejoc.202000916.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ejoc.202000916.xml",
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "25",
         "10.1002_esp.5058",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_esp.5058.pdf",
         null,
         "test",
         "[{'dataset_id': 'https://doi.org/10.5061/dryad.jh9w0vt9t', 'type': 'Primary'}]"
        ],
        [
         "26",
         "10.1002_esp.5090",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_esp.5090.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_esp.5090.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.5066/p9353101', 'type': 'Secondary'}]"
        ],
        [
         "27",
         "10.1002_mp.14424",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_mp.14424.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_mp.14424.xml",
         "test",
         "[{'dataset_id': 'https://doi.org/10.7937/k9/tcia.2015.pf0m9rei', 'type': 'Secondary'}, {'dataset_id': 'https://doi.org/10.7937/tcia.2020.6c7y-gq39', 'type': 'Primary'}]"
        ],
        [
         "28",
         "10.1002_nafm.10870",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_nafm.10870.pdf",
         null,
         "test",
         "[{'dataset_id': 'https://doi.org/10.5066/p9gtumay', 'type': 'Primary'}]"
        ],
        [
         "29",
         "10.1007_jhep07(2018)134",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1007_jhep07(2018)134.pdf",
         null,
         "test",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 30
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>pdf_file_path</th>\n",
       "      <th>xml_file_path</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>dataset_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1002_2017jc013030</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.17882/4938...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1002_anie.201916483</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1002_anie.202005531</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1002_anie.202007717</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1002_chem.201902131</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1002_chem.201903120</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.1002_chem.202000235</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1002_chem.202001412</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.1002_chem.202001668</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.1002_chem.202003167</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.1002_cssc.202201821</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.1002_ece3.3985</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.1002_ece3.4466</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5061/dryad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.1002_ece3.5260</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5061/dryad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.1002_ece3.5395</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.1002_ece3.6144</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5061/dryad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.1002_ece3.6303</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5061/dryad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.1002_ece3.6784</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.1002_ece3.961</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.1002_ece3.9627</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5061/dryad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.1002_ecs2.1280</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5061/dryad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.1002_ecs2.4619</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.25349/d9qw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.1002_ejic.201900904</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.1002_ejoc.202000139</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.1002_ejoc.202000916</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.1002_esp.5058</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5061/dryad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.1002_esp.5090</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5066/p9353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.1002_mp.14424</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.7937/k9/tc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.1002_nafm.10870</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5066/p9gtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.1007_jhep07(2018)134</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article_id  \\\n",
       "0      10.1002_2017jc013030   \n",
       "1    10.1002_anie.201916483   \n",
       "2    10.1002_anie.202005531   \n",
       "3    10.1002_anie.202007717   \n",
       "4    10.1002_chem.201902131   \n",
       "5    10.1002_chem.201903120   \n",
       "6    10.1002_chem.202000235   \n",
       "7    10.1002_chem.202001412   \n",
       "8    10.1002_chem.202001668   \n",
       "9    10.1002_chem.202003167   \n",
       "10   10.1002_cssc.202201821   \n",
       "11        10.1002_ece3.3985   \n",
       "12        10.1002_ece3.4466   \n",
       "13        10.1002_ece3.5260   \n",
       "14        10.1002_ece3.5395   \n",
       "15        10.1002_ece3.6144   \n",
       "16        10.1002_ece3.6303   \n",
       "17        10.1002_ece3.6784   \n",
       "18         10.1002_ece3.961   \n",
       "19        10.1002_ece3.9627   \n",
       "20        10.1002_ecs2.1280   \n",
       "21        10.1002_ecs2.4619   \n",
       "22   10.1002_ejic.201900904   \n",
       "23   10.1002_ejoc.202000139   \n",
       "24   10.1002_ejoc.202000916   \n",
       "25         10.1002_esp.5058   \n",
       "26         10.1002_esp.5090   \n",
       "27         10.1002_mp.14424   \n",
       "28       10.1002_nafm.10870   \n",
       "29  10.1007_jhep07(2018)134   \n",
       "\n",
       "                                        pdf_file_path  \\\n",
       "0   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "1   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "2   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "3   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "4   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "5   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "6   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "7   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "8   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "9   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "10  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "11  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "12  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "13  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "14  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "15  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "16  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "17  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "18  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "19  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "20  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "21  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "22  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "23  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "24  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "25  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "26  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "27  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "28  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "29  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "\n",
       "                                        xml_file_path dataset_type  \\\n",
       "0   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "1   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "2   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "3   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "4   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "5   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "6   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "7   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "8   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "9   ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "10  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "11  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "12  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "13  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "14  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "15  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "16  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "17  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "18  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "19  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "20                                                NaN         test   \n",
       "21  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "22  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "23                                                NaN         test   \n",
       "24  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "25                                                NaN         test   \n",
       "26  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "27  ./kaggle/input/make-data-count-finding-data-re...         test   \n",
       "28                                                NaN         test   \n",
       "29                                                NaN         test   \n",
       "\n",
       "                                         dataset_info  \n",
       "0   [{'dataset_id': 'https://doi.org/10.17882/4938...  \n",
       "1      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "2      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "3      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "4      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "5      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "6      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "7      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "8      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "9      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "10                                                NaN  \n",
       "11     [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "12  [{'dataset_id': 'https://doi.org/10.5061/dryad...  \n",
       "13  [{'dataset_id': 'https://doi.org/10.5061/dryad...  \n",
       "14     [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "15  [{'dataset_id': 'https://doi.org/10.5061/dryad...  \n",
       "16  [{'dataset_id': 'https://doi.org/10.5061/dryad...  \n",
       "17     [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "18     [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "19  [{'dataset_id': 'https://doi.org/10.5061/dryad...  \n",
       "20  [{'dataset_id': 'https://doi.org/10.5061/dryad...  \n",
       "21  [{'dataset_id': 'https://doi.org/10.25349/d9qw...  \n",
       "22     [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "23     [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "24     [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "25  [{'dataset_id': 'https://doi.org/10.5061/dryad...  \n",
       "26  [{'dataset_id': 'https://doi.org/10.5066/p9353...  \n",
       "27  [{'dataset_id': 'https://doi.org/10.7937/k9/tc...  \n",
       "28  [{'dataset_id': 'https://doi.org/10.5066/p9gtu...  \n",
       "29     [{'dataset_id': 'Missing', 'type': 'Missing'}]  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f2525aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen model and tokenizer from: C:\\Users\\jim\\.cache\\kagglehub\\models\\qwen-lm\\qwen-3\\transformers\\0.6b\\1\n"
     ]
    }
   ],
   "source": [
    "eval_model = QwenModelEval(QWEN_BASE_MODEL_PATH, sys_prompt=\"You are a chatbot.\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8bee422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How many r's in strawberries?\n",
      "Preparing input for user: How many r's in strawberries?\n",
      "Generating response for user input:\n",
      "Parsing response from generated IDs...\n",
      "Bot: ('There are 2 \\'r\\'s in the word \"strawberries\".', '<think>\\nOkay, the user is asking how many \\'r\\'s are in \"strawberries\". Let me start by breaking down the word. \"Strawberries\" is spelled S-T-R-A-W-B-E-R-R-I-N-G-S. Let me count each \\'r\\' here. \\n\\nFirst letter: S, no \\'r\\'. Second: T, no. Third: R, one \\'r\\'. Fourth: A, no. Fifth: W, no. Sixth: B, no. Seventh: E, no. Eighth: R, another \\'r\\'. Ninth: I, no. Tenth: N, no. Eleventh: G, no. So that\\'s two \\'r\\'s in total. \\n\\nWait, maybe I should double-check. Let me write it out again: S-T-R-A-W-B-E-R-R-I-N-G-S. Yes, the third and eighth letters are both \\'r\\'s. So two \\'r\\'s. The user might be testing if I can count them correctly. I should make sure there\\'s no other \\'r\\'s I missed. No, I think that\\'s all. So the answer is two.\\n</think>')\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage of eval_model ---\n",
    "\n",
    "# First input (without /think or /no_think tags, thinking mode is enabled by default)\n",
    "user_input_1 = \"How many r's in strawberries?\"\n",
    "print(f\"User: {user_input_1}\")\n",
    "response_1 = eval_model.generate_response(user_input_1)\n",
    "print(f\"Bot: {response_1}\")\n",
    "print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. Data Preparation for LLM Training (Revised for Combined Task) ---\n",
    "\n",
    "def load_base_llm_for_training():\n",
    "    \"\"\"Loads the base Qwen model and tokenizer for fine-tuning.\"\"\"\n",
    "    global llm_tokenizer, llm_model\n",
    "    if not AutoModelForCausalLM or not QWEN_BASE_MODEL_PATH:\n",
    "        print(\"LLM components not available or base model path not set. Skipping LLM loading.\")\n",
    "        return False\n",
    "    try:\n",
    "        print(f\"Loading Qwen tokenizer from: {QWEN_BASE_MODEL_PATH}\")\n",
    "        llm_tokenizer = AutoTokenizer.from_pretrained(QWEN_BASE_MODEL_PATH, trust_remote_code=True)\n",
    "        if llm_tokenizer.pad_token is None:\n",
    "            llm_tokenizer.pad_token = llm_tokenizer.eos_token\n",
    "            print(\"Set tokenizer.pad_token to tokenizer.eos_token\")\n",
    "\n",
    "        print(f\"Loading Qwen model from: {QWEN_BASE_MODEL_PATH}\")\n",
    "        llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "            QWEN_BASE_MODEL_PATH,\n",
    "            torch_dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float32,\n",
    "            device_map=\"auto\", # Automatically uses GPU if available\n",
    "            trust_remote_code=True,\n",
    "            # load_in_8bit=True if bnb else False # Uncomment if bitsandbytes is used\n",
    "        )\n",
    "        print(f\"Base LLM loaded successfully on {llm_model.device}.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading base LLM for training: {e}\")\n",
    "        llm_tokenizer, llm_model = None, None # Reset to None on failure\n",
    "        return False\n",
    "\n",
    "def prepare_training_data_for_llm(\n",
    "    training_df: pd.DataFrame,\n",
    "    all_article_texts: dict[str, str],\n",
    "    tokenizer_max_length: int\n",
    ") -> Dataset:\n",
    "    \"\"\"\n",
    "    Prepares training data for LLM fine-tuning, aggregating dataset IDs and classifications\n",
    "    per article and formatting into ChatML JSON output.\n",
    "    \"\"\"\n",
    "    formatted_examples = []\n",
    "\n",
    "    # Group training data by article_id to get all datasets for each article\n",
    "    # This creates a dictionary where keys are article_ids and values are lists of dataset dicts\n",
    "    grouped_training_data = training_df.groupby('article_id').apply(\n",
    "        lambda x: [{\"dataset_id\": row['dataset_id'], \"classification\": row['label']} for _, row in x]\n",
    "    ).to_dict()\n",
    "\n",
    "    # Get all article IDs for which we have text content\n",
    "    all_article_ids_with_text = set(all_article_texts.keys())\n",
    "    \n",
    "    # Iterate through all articles for which we have text (these are our potential training examples)\n",
    "    for article_id in all_article_ids_with_text:\n",
    "        article_text = all_article_texts.get(article_id, \"\")\n",
    "        if not article_text:\n",
    "            print(f\"Warning: Article text for {article_id} not found. Skipping training example.\")\n",
    "            continue\n",
    "\n",
    "        # Truncate article text to fit within the model's context window\n",
    "        # Reserve tokens for the prompt and the expected JSON response.\n",
    "        # A typical Qwen 1.5 model has 32768 max_seq_length.\n",
    "        # 512 tokens for prompt/response is a safe estimate.\n",
    "        truncated_article_text = article_text[:tokenizer_max_length - 512] \n",
    "\n",
    "        # Determine the ground truth output for this article\n",
    "        if article_id in grouped_training_data:\n",
    "            # Article has datasets, format them as JSON\n",
    "            ground_truth_datasets = grouped_training_data[article_id]\n",
    "            assistant_response_json = json.dumps(ground_truth_datasets, ensure_ascii=False)\n",
    "        else:\n",
    "            # Article has no datasets in training data, so the model should output an empty list.\n",
    "            # This explicitly trains the model to output '[]' for \"Missing\" cases.\n",
    "            assistant_response_json = \"[]\"\n",
    "            # print(f\"Info: Article {article_id} has no datasets in training data. Training to output '[]'.\")\n",
    "\n",
    "        # Construct the user message for the LLM\n",
    "        user_message = f\"\"\"\n",
    "Article Text:\n",
    "{truncated_article_text}\n",
    "\n",
    "Task: Identify all datasets or databases used in this research article and classify each as \"Primary\" (if created by the authors for this research) or \"Secondary\" (if an existing dataset used in this research).\n",
    "\n",
    "Output Format: Provide a JSON list of objects. Each object should have \"dataset_id\" and \"classification\" keys. If no datasets are identified, return an empty JSON list: [].\n",
    "\"\"\"\n",
    "        # Construct the full ChatML formatted string for SFTTrainer\n",
    "        # The trainer will use this entire string as the 'text' field.\n",
    "        chatml_formatted_string = f\"<|im_start|>system\\nYou are an expert research assistant. Your task is to extract and classify datasets from scientific articles.<|im_end|>\\n<|im_start|>user\\n{user_message.strip()}<|im_end|>\\n<|im_start|>assistant\\n{assistant_response_json}<|im_end|>\"\n",
    "        \n",
    "        formatted_examples.append({\"text\": chatml_formatted_string})\n",
    "\n",
    "    if not formatted_examples:\n",
    "        raise ValueError(\"No training examples could be prepared. Check your data and article texts.\")\n",
    "\n",
    "    return Dataset.from_list(formatted_examples)\n",
    "\n",
    "# --- 3. LLM Model Training (Fine-tuning) ---\n",
    "\n",
    "# Attempt to load tokenizer and model if not already loaded (e.g., if previous training failed or was skipped)\n",
    "if llm_model is None:\n",
    "    load_base_llm_for_training()\n",
    "\n",
    "if llm_model and not training_df.empty and Dataset: # Ensure Dataset is imported\n",
    "    print(\"\\n--- Preparing data for Fine-tuning (Combined Task) ---\")\n",
    "    # Use the model's max_length for context, or a reasonable default if tokenizer isn't loaded\n",
    "    max_len = llm_tokenizer.model_max_length if llm_tokenizer else 4096 \n",
    "    train_dataset = prepare_training_data_for_llm(training_df, all_article_texts, max_len)\n",
    "    \n",
    "    print(f\"Prepared {len(train_dataset)} examples for fine-tuning.\")\n",
    "    print(\"Example formatted training instance (first 500 chars):\")\n",
    "    print(train_dataset[0]['text'][:500])\n",
    "\n",
    "    print(\"\\n--- Starting Fine-tuning (Combined Task) ---\")\n",
    "    try:\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"{FINE_TUNED_MODEL_OUTPUT_DIR}/checkpoints\",\n",
    "            num_train_epochs=1,  # Start with 1 epoch, adjust as needed\n",
    "            per_device_train_batch_size=1, # Adjust based on VRAM\n",
    "            gradient_accumulation_steps=4, # Effective batch size = 1 * 4 = 4\n",
    "            learning_rate=2e-5,\n",
    "            logging_steps=10,\n",
    "            save_steps=50, # Save checkpoints periodically\n",
    "            fp16=torch.cuda.is_available() and not torch.cuda.is_bf16_supported(),\n",
    "            bf16=torch.cuda.is_available() and torch.cuda.is_bf16_supported(),\n",
    "            optim=\"paged_adamw_8bit\", # Good for memory efficiency if bitsandbytes is installed\n",
    "            # report_to=\"none\", # Disable logging to external services\n",
    "            # max_steps=100, # For quick testing\n",
    "        )\n",
    "\n",
    "        trainer = SFTTrainer(\n",
    "            model=llm_model,\n",
    "            tokenizer=llm_tokenizer,\n",
    "            train_dataset=train_dataset,\n",
    "            dataset_text_field=\"text\", # This field contains the full ChatML string\n",
    "            args=training_args,\n",
    "            max_seq_length=max_len, # Use the model's full context length\n",
    "            packing=False, # Set to True if your inputs are much shorter than max_seq_length\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        print(\"Fine-tuning completed.\")\n",
    "\n",
    "        print(f\"Saving fine-tuned model to: {FINE_TUNED_MODEL_OUTPUT_DIR}\")\n",
    "        trainer.save_model(FINE_TUNED_MODEL_OUTPUT_DIR)\n",
    "        print(\"Model and tokenizer saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during fine-tuning: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        llm_model = None # Mark model as failed to load/train\n",
    "else:\n",
    "    print(\"Skipping LLM fine-tuning due to missing training data or LLM components.\")\n",
    "\n",
    "\n",
    "# --- 4. LLM-based Extraction & Classification (Inference) ---\n",
    "\n",
    "# Load the fine-tuned model for inference (if training was successful)\n",
    "# If training was skipped or failed, this will attempt to load from the base path or fail.\n",
    "if inference_model is None: # Only load if not already loaded\n",
    "    if AutoModelForCausalLM: # Check if transformers is available\n",
    "        if os.path.exists(FINE_TUNED_MODEL_OUTPUT_DIR) and os.path.isdir(FINE_TUNED_MODEL_OUTPUT_DIR):\n",
    "            MODEL_TO_LOAD = FINE_TUNED_MODEL_OUTPUT_DIR\n",
    "            print(f\"Loading fine-tuned model for inference from: {MODEL_TO_LOAD}\")\n",
    "        else:\n",
    "            MODEL_TO_LOAD = QWEN_BASE_MODEL_PATH\n",
    "            print(f\"Fine-tuned model not found. Loading base model for inference from: {MODEL_TO_LOAD}\")\n",
    "\n",
    "        try:\n",
    "            inference_tokenizer = AutoTokenizer.from_pretrained(MODEL_TO_LOAD, trust_remote_code=True)\n",
    "            if inference_tokenizer.pad_token is None:\n",
    "                inference_tokenizer.pad_token = inference_tokenizer.eos_token\n",
    "            inference_model = AutoModelForCausalLM.from_pretrained(\n",
    "                MODEL_TO_LOAD,\n",
    "                torch_dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float32,\n",
    "                device_map=\"auto\",\n",
    "                trust_remote_code=True\n",
    "            ).eval() # Set to evaluation mode\n",
    "            print(f\"Inference LLM loaded successfully on {inference_model.device}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading inference LLM from {MODEL_TO_LOAD}: {e}\")\n",
    "            inference_model, inference_tokenizer = None, None\n",
    "    else:\n",
    "        print(\"Transformers library not available. Cannot load LLM for inference.\")\n",
    "\n",
    "\n",
    "def extract_and_classify_with_llm(article_text: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Uses the loaded LLM to extract dataset IDs and classify them.\n",
    "    Returns a list of dictionaries like [{\"dataset_id\": \"...\", \"classification\": \"...\"}].\n",
    "    Returns an empty list if LLM is unavailable or parsing fails.\n",
    "    \"\"\"\n",
    "    if not inference_model or not inference_tokenizer:\n",
    "        print(\"  LLM unavailable for extraction/classification.\")\n",
    "        return [] # Return empty list if LLM is not loaded\n",
    "\n",
    "    # Truncate article text for inference if it exceeds model's context window\n",
    "    # Use the same max_length as during training for consistency\n",
    "    max_inference_context_length = inference_tokenizer.model_max_length - 256 # Reserve tokens for prompt and response\n",
    "    truncated_article_text = article_text[:max_inference_context_length]\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "Article Text:\n",
    "{truncated_article_text}\n",
    "\n",
    "Task: Identify all datasets or databases used in this research article and classify each as \"Primary\" (if created by the authors for this research) or \"Secondary\" (if an existing dataset used in this research).\n",
    "\n",
    "Output Format: Provide a JSON list of objects. Each object should have \"dataset_id\" and \"classification\" keys. If no datasets are identified, return an empty JSON list: [].\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert research assistant. Your task is to extract and classify datasets from scientific articles.\"},\n",
    "        {\"role\": \"user\", \"content\": user_message.strip()}\n",
    "    ]\n",
    "    \n",
    "    input_ids = inference_tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(inference_model.device)\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            outputs = inference_model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=512, # Allow more tokens for multiple dataset outputs\n",
    "                pad_token_id=inference_tokenizer.eos_token_id,\n",
    "                eos_token_id=inference_tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "            )\n",
    "        \n",
    "        response_text = inference_tokenizer.decode(\n",
    "            outputs[0][input_ids.shape[1]:],\n",
    "            skip_special_tokens=False # Keep special tokens to remove <|im_end|> explicitly\n",
    "        ).strip()\n",
    "        response_text = response_text.replace(\"<|im_end|>\", \"\").strip()\n",
    "        \n",
    "        print(f\"  LLM raw response: '{response_text}'\")\n",
    "\n",
    "        # Attempt to parse the JSON output\n",
    "        try:\n",
    "            parsed_data = json.loads(response_text)\n",
    "            if isinstance(parsed_data, list):\n",
    "                # Validate structure: each item should be a dict with 'dataset_id' and 'classification'\n",
    "                valid_datasets = []\n",
    "                for item in parsed_data:\n",
    "                    if isinstance(item, dict) and 'dataset_id' in item and 'classification' in item:\n",
    "                        # Basic validation for classification label\n",
    "                        if item['classification'] in [\"Primary\", \"Secondary\"]:\n",
    "                            valid_datasets.append(item)\n",
    "                        else:\n",
    "                            print(f\"  Warning: Invalid classification '{item['classification']}' for dataset '{item.get('dataset_id', 'N/A')}'. Skipping.\")\n",
    "                    else:\n",
    "                        print(f\"  Warning: Malformed JSON object: {item}. Skipping.\")\n",
    "                return valid_datasets\n",
    "            else:\n",
    "                print(f\"  Warning: LLM did not return a JSON list: {response_text}\")\n",
    "                return []\n",
    "        except json.JSONDecodeError as jde:\n",
    "            print(f\"  Error decoding JSON from LLM response: {jde}. Raw response: '{response_text}'\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during LLM generation: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Main Processing Loop for all articles (Revised) ---\n",
    "print(\"\\n--- Starting Article Processing and Classification (LLM-driven) ---\")\n",
    "final_results = []\n",
    "\n",
    "for article_id, article_text in all_article_texts.items():\n",
    "    print(f\"\\nProcessing article: {article_id}\")\n",
    "    \n",
    "    # LLM directly extracts and classifies\n",
    "    identified_datasets = extract_and_classify_with_llm(article_text)\n",
    "    \n",
    "    if not identified_datasets:\n",
    "        # If LLM returns an empty list, classify the article as \"Missing\"\n",
    "        print(f\"  LLM identified no datasets for {article_id}. Classifying as 'Missing'.\")\n",
    "        final_results.append({\n",
    "            \"article_id\": article_id,\n",
    "            \"dataset_id\": \"N/A\", # Indicate no specific dataset ID\n",
    "            \"classification_label\": \"Missing\"\n",
    "        })\n",
    "    else:\n",
    "        print(f\"  LLM identified {len(identified_datasets)} dataset(s) for {article_id}.\")\n",
    "        for item in identified_datasets:\n",
    "            final_results.append({\n",
    "                \"article_id\": article_id,\n",
    "                \"dataset_id\": item.get(\"dataset_id\", \"Unknown\"), # Use .get() for safety\n",
    "                \"classification_label\": item.get(\"classification\", \"Uncertain_LLM\")\n",
    "            })\n",
    "\n",
    "\n",
    "# --- 5. Results & Output ---\n",
    "\n",
    "print(\"\\n--- Final Results ---\")\n",
    "if final_results:\n",
    "    results_df = pd.DataFrame(final_results)\n",
    "    print(results_df.head(10)) # Print first 10 rows\n",
    "    \n",
    "    # Save to CSV\n",
    "    results_df.to_csv(FINAL_RESULTS_CSV_PATH, index=False)\n",
    "    print(f\"\\nResults saved to: {FINAL_RESULTS_CSV_PATH}\")\n",
    "else:\n",
    "    print(\"No results generated.\")\n",
    "\n",
    "print(\"\\nProcessing complete, Jim!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
