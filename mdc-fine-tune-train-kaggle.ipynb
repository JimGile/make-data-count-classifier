{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3195093d",
   "metadata": {},
   "source": [
    "#### 1. Setup and Dependencies\n",
    "\n",
    "First, ensure all necessary libraries are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ca2607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# 1.1. Install necessary libraries\n",
    "# Use !pip install for notebook environment\n",
    "# !pip install transformers trl accelerate bitsandbytes sentencepiece lxml PyMuPDF spacy peft\n",
    "# !python -m spacy download en_core_web_sm # Download a small spaCy model\n",
    "\n",
    "# 1.2. Import Libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Set, List, Optional, Dict, Any\n",
    "\n",
    "import fitz # PyMuPDF\n",
    "from lxml import etree # For XML parsing\n",
    "import spacy\n",
    "import kagglehub\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils.quantization_config import BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import gc # For garbage collection\n",
    "\n",
    "# For KaggleHub integration (assuming it's set up or models are downloaded)\n",
    "# You might need to install kagglehub if you plan to use it directly for model download\n",
    "# !pip install kagglehub\n",
    "\n",
    "# 1.3. Configure CUDA for local GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache() # Clear GPU memory\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1ab706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classes from local utility file\n",
    "import mdc_data_processing_utils\n",
    "\n",
    "# If mdc_data_processing_utils.py has been changed and saved.\n",
    "# To load the changes without restarting the kernel:\n",
    "import importlib\n",
    "importlib.reload(mdc_data_processing_utils)\n",
    "\n",
    "# Now, any calls to functions from mdc_data_processing_utils\n",
    "# will use the newly reloaded code.\n",
    "from mdc_data_processing_utils import (\n",
    "    ArticleData,\n",
    "    DatasetCitation,\n",
    "    LlmTrainingData,\n",
    "    SubmissionData,\n",
    "    MdcFileTextExtractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b02acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for file paths and model configurations\n",
    "BASE_INPUT_DIR = './kaggle/input/make-data-count-finding-data-references'\n",
    "BASE_OUTPUT_DIR = \"./kaggle/working\"\n",
    "\n",
    "# Define directories for articles in train and test sets\n",
    "TRAIN_DATA_DIR = os.path.join(BASE_INPUT_DIR, 'train')\n",
    "TEST_DATA_DIR = os.path.join(BASE_INPUT_DIR, 'test')\n",
    "TRAIN_LABELS_PATH = os.path.join(BASE_INPUT_DIR, 'train_labels.csv')\n",
    "\n",
    "# Define the path to the few-shot examples CSV\n",
    "FEW_SHOT_CSV_PATH = os.path.join(BASE_OUTPUT_DIR, \"few_shot_examples.csv\")\n",
    "\n",
    "# Define the base model path\n",
    "QWEN_BASE_MODEL_PATH = kagglehub.model_download(\"qwen-lm/qwen-3/transformers/0.6b\")\n",
    "\n",
    "# Output directory for the fine-tuned model and results\n",
    "FINE_TUNED_MODEL_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, \"results\")\n",
    "SAMPLE_SUBMISSION_PATH = os.path.join(BASE_OUTPUT_DIR, \"submission.csv\")\n",
    "\n",
    "# Load spaCy model for sentence segmentation and potentially other NLP tasks\n",
    "# python -m spacy download en_core_web_sm \n",
    "NLP_SPACY = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "FEW_SHOT_EXAMPLES = \"\"\"\n",
    "### Example 1 (Primary)\n",
    "Article Abstract: We present a novel dataset of forest growth measurements collected over 5 years in the Amazon rainforest. This data was used to develop a new model of carbon sequestration.\n",
    "Dataset ID: 10.5061/dryad.r6nq870\n",
    "Data Citation Context: The raw data for this study, including all measurements and derived variables, has been deposited in the Dryad Digital Repository (dryad.2f62927). This newly generated dataset supports the findings of our research.\n",
    "Classification: Primary\n",
    "\n",
    "### Example 2 (Primary - Another Example)\n",
    "Article Abstract: We developed a new computational model for protein folding and generated a large dataset of simulated protein structures.\n",
    "Dataset ID: PDB12345\n",
    "Data Citation Context: The simulated protein structures (PDB12345) are available in the Protein Data Bank and were generated as part of this study's novel computational approach.\n",
    "Classification: Primary\n",
    "\n",
    "### Example 3 (Primary - Ambiguous Case)\n",
    "Article Abstract: This study utilized both newly collected field data and some previously published climate data to analyze ecosystem changes.\n",
    "Dataset ID: 10.5281/zenodo.7074790\n",
    "Data Citation Context: Data Availability Statement The data that support the findings of this study are openly available in zenodo at https://doi.org/10.5281/zenodo.7074790.(https://doi.org/10.5281/zenodo.7074790).\n",
    "Classification: Primary\n",
    "\n",
    "### Example 4 (Secondary)\n",
    "Article Abstract: We re-analyzed publicly available gene expression data to identify new biomarkers for cancer.\n",
    "Dataset ID: GSE12345\n",
    "Data Citation Context: We downloaded the gene expression profiles from the GEO database (GSE12345), which were previously published by Smith et al. (2020). This existing dataset was re-analyzed for our current study.\n",
    "Classification: Secondary\n",
    "\n",
    "### Example 5 (Missing - Irrelevant Context)\n",
    "Article Abstract: Implications for intraplate earthquake behavior and the geomorphic longevity of bedrock fault scarps in a low strain-rate cratonic region.\n",
    "Dataset ID: 10.1080/08120090802546977\n",
    "Data Citation Context: (2009) Constraints on the current rate of deformation and surface uplift of the Australian continent from a new seismic database and low-T thermochronological data. Australian Journal of Earth Sciences, 56(2), 99-110. https://doi.org/(https://doi.org/10.1080/08120090802546977).\n",
    "Classification: Missing\n",
    "\n",
    "### Example 6 (Missing - No context)\n",
    "Article Abstract: Our study investigates the social dynamics of ant colonies.\n",
    "Dataset ID: 10.1038/s41586-023-06000-0\n",
    "Data Citation Context: \n",
    "Classification: Missing\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b4259",
   "metadata": {},
   "source": [
    "#### 3. Data Loading and Initial Preprocessing\n",
    "\n",
    "This section will cover how to load the raw competition data (full text articles and labels) and begin structuring it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5d12b",
   "metadata": {},
   "source": [
    "#### Load Labeled Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438f57fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labeled training data from: ./kaggle/input/make-data-count-finding-data-references\\train_labels.csv\n",
      "Training labels shape: (1028, 3)\n",
      "Example grouped training data for article_id '10.1002_2017jc013030': [{'dataset_id': 'https://doi.org/10.17882/49388', 'type': 'Primary'}]\n",
      "Files paths shape: (262, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "xml_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ground_truth_dataset_info",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "f4c8cda8-73ca-4e39-ba27-50b2ea0d4f85",
       "rows": [
        [
         "17",
         "10.1107_s2052252514012081",
         "./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s2052252514012081.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\train\\XML\\10.1107_s2052252514012081.xml",
         "train",
         "[{'dataset_id': 'Missing', 'type': 'Missing'}]"
        ],
        [
         "158",
         "10.3897_neobiota.82.87455",
         "./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3897_neobiota.82.87455.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\train\\XML\\10.3897_neobiota.82.87455.xml",
         "train",
         "[{'dataset_id': 'https://doi.org/10.15468/dl.yjd4cg', 'type': 'Secondary'}, {'dataset_id': 'https://doi.org/10.15468/dl.yu2xpv', 'type': 'Secondary'}]"
        ],
        [
         "240",
         "10.12688_f1000research.13483.1",
         "./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.12688_f1000research.13483.1.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\train\\XML\\10.12688_f1000research.13483.1.xml",
         "train",
         "[{'dataset_id': 'https://doi.org/10.5256/f1000research.13483.d188591', 'type': 'Primary'}]"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>pdf_file_path</th>\n",
       "      <th>xml_file_path</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>ground_truth_dataset_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.1107_s2052252514012081</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'dataset_id': 'Missing', 'type': 'Missing'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>10.3897_neobiota.82.87455</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.15468/dl.y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>10.12688_f1000research.13483.1</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>train</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5256/f1000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         article_id  \\\n",
       "17        10.1107_s2052252514012081   \n",
       "158       10.3897_neobiota.82.87455   \n",
       "240  10.12688_f1000research.13483.1   \n",
       "\n",
       "                                         pdf_file_path  \\\n",
       "17   ./kaggle/input/make-data-count-finding-data-re...   \n",
       "158  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "240  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "\n",
       "                                         xml_file_path dataset_type  \\\n",
       "17   ./kaggle/input/make-data-count-finding-data-re...        train   \n",
       "158  ./kaggle/input/make-data-count-finding-data-re...        train   \n",
       "240  ./kaggle/input/make-data-count-finding-data-re...        train   \n",
       "\n",
       "                             ground_truth_dataset_info  \n",
       "17      [{'dataset_id': 'Missing', 'type': 'Missing'}]  \n",
       "158  [{'dataset_id': 'https://doi.org/10.15468/dl.y...  \n",
       "240  [{'dataset_id': 'https://doi.org/10.5256/f1000...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_file_paths(dataset_type_dir: str) -> pd.DataFrame: \n",
    "    pdf_path = os.path.join(dataset_type_dir, 'PDF')\n",
    "    xml_path = os.path.join(dataset_type_dir, 'XML')\n",
    "    dataset_type = os.path.basename(dataset_type_dir)\n",
    "    pdf_files = [f for f in os.listdir(pdf_path) if f.endswith('.pdf')]\n",
    "    xml_files = [f for f in os.listdir(xml_path) if f.endswith('.xml')]\n",
    "    df_pdf = pd.DataFrame({\n",
    "        'article_id': [f.replace('.pdf', '') for f in pdf_files],\n",
    "        'pdf_file_path': [os.path.join(pdf_path, f) for f in pdf_files]\n",
    "    })\n",
    "    df_xml = pd.DataFrame({\n",
    "        'article_id': [f.replace('.xml', '') for f in xml_files],\n",
    "        'xml_file_path': [os.path.join(xml_path, f) for f in xml_files]\n",
    "    })\n",
    "    merge_df = pd.merge(df_pdf, df_xml, on='article_id', how='outer', suffixes=('_pdf', '_xml'), validate=\"one_to_many\")\n",
    "    merge_df['dataset_type'] = dataset_type\n",
    "    return merge_df\n",
    "\n",
    "# Load the labeled training data CSV file\n",
    "print(f\"Loading labeled training data from: {TRAIN_LABELS_PATH}\")\n",
    "train_labels_df = pd.read_csv(TRAIN_LABELS_PATH)\n",
    "print(f\"Training labels shape: {train_labels_df.shape}\")\n",
    "\n",
    "# Group training data by article_id to get all datasets for each article\n",
    "# This creates a dictionary where keys are article_ids and values are lists of dataset dicts\n",
    "grouped_training_data = {}\n",
    "for article_id, group_df in train_labels_df.groupby('article_id'):\n",
    "    grouped_training_data[article_id] = group_df[['dataset_id', 'type']].to_dict('records')\n",
    "\n",
    "# Example usage of grouped_training_data\n",
    "print(f\"Example grouped training data for article_id '10.1002_2017jc013030': {grouped_training_data['10.1002_2017jc013030']}\")\n",
    "\n",
    "# Just for testing, always set to the TEST_DATA_DIR\n",
    "base_file_dir = TRAIN_DATA_DIR\n",
    "\n",
    "# Load file paths for base directory\n",
    "file_paths_df = load_file_paths(base_file_dir)\n",
    "file_paths_df['pdf_file_path'] = file_paths_df['pdf_file_path'].fillna('')\n",
    "file_paths_df['xml_file_path'] = file_paths_df['xml_file_path'].fillna('')\n",
    "\n",
    "# Merge the file paths with the grouped_training_data\n",
    "file_paths_df['ground_truth_dataset_info'] = file_paths_df['article_id'].map(grouped_training_data)\n",
    "file_paths_df['ground_truth_dataset_info'] = file_paths_df['ground_truth_dataset_info'].fillna('')\n",
    "\n",
    "# Reduce the file paths DataFrame to only those with ground truth dataset info and get a sample\n",
    "# This is to ensure we have a manageable dataset for training\n",
    "file_paths_df = file_paths_df[file_paths_df['ground_truth_dataset_info'].astype(bool)]\n",
    "file_paths_df = file_paths_df.reset_index(drop=True)\n",
    "file_paths_df = file_paths_df.sample(frac=.5, random_state=42).reset_index(drop=True)  # Shuffle the DataFrame\n",
    "print(f\"Files paths shape: {file_paths_df.shape}\")\n",
    "display(file_paths_df.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f0763",
   "metadata": {},
   "source": [
    "#### Define Training Data Extract Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2b2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_training_data_for_llm(file_paths_df: pd.DataFrame) -> list[dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Extracts article data for training set with ground truth.\n",
    "    \n",
    "    Args:\n",
    "        file_paths_df (pd.DataFrame): DataFrame containing file paths and ground truth info.\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, ArticleData]: Dictionary mapping article IDs to ArticleData objects.\n",
    "    \"\"\"\n",
    "    training_data_for_llm: list[dict[str, str]] = [] # This will be a list of LlmTrainingData for the LLM training dataset\n",
    "    for i, row in tqdm(file_paths_df.iterrows(), total=len(file_paths_df)):\n",
    "        article_id = row['article_id']\n",
    "        filepath = row['pdf_file_path'] if row['pdf_file_path'] else row['xml_file_path']\n",
    "        ground_truth_list = row['ground_truth_dataset_info'] if 'ground_truth_dataset_info' in row else []\n",
    "\n",
    "        file_extractor = MdcFileTextExtractor(article_id, filepath)\n",
    "        article_data = file_extractor.extract_article_data_for_training(NLP_SPACY, ground_truth_list)\n",
    "        training_data_for_llm.extend(article_data.get_data_for_llm())\n",
    "\n",
    "    print(f\"Loaded training data for {len(training_data_for_llm)} articles.\")\n",
    "    return training_data_for_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aeda081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "xml_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ground_truth_dataset_info",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "deb41cdf-991d-4258-afa4-8dc623421de7",
       "rows": [
        [
         "154",
         "10.1002_esp.5058",
         "./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_esp.5058.pdf",
         "",
         "train",
         "[{'dataset_id': 'https://doi.org/10.5061/dryad.jh9w0vt9t', 'type': 'Primary'}]"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>pdf_file_path</th>\n",
       "      <th>xml_file_path</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>ground_truth_dataset_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>10.1002_esp.5058</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>[{'dataset_id': 'https://doi.org/10.5061/dryad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           article_id                                      pdf_file_path  \\\n",
       "154  10.1002_esp.5058  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "\n",
       "    xml_file_path dataset_type  \\\n",
       "154                      train   \n",
       "\n",
       "                             ground_truth_dataset_info  \n",
       "154  [{'dataset_id': 'https://doi.org/10.5061/dryad...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing, let's extract training data for a specific article\n",
    "sample_file_paths_df = file_paths_df.loc[file_paths_df['article_id'] == '10.1002_esp.5058']\n",
    "sample_file_paths_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef756a4e",
   "metadata": {},
   "source": [
    "#### 4. Advanced Preprocessing: Extracting Dataset Mentions and Context (Training)\n",
    "\n",
    "Use regex to find the given dataset IDs from the training_labels and then use spaCy to extract surrounding sentences as context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f23263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c96cc841b8426abe8543c2a6429f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.7717_peerj.12422.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0198382.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_chem.202000235.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_2041-210x.12453.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41597-019-0101-y.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12974-020-01860-y.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.7717_peerj.13193.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3390_s23177333.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1080_22221751.2020.1738277.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1103_physrevresearch.4.023008.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_ece3.3985.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.5194_tc-17-3617-2023.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41467-019-10357-z.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1980-5918.033.ao15.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3390_molecules191017026.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s1600536808011148.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_anie.202005531.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s2052252514012081.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1364_oe.25.001985.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1098_rspb.2015.1498.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13046-018-0843-y.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1414-431x20198292.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12920-020-00737-6.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12916-019-1469-4.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13072-019-0322-5.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12920-018-0426-y.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12868-018-0468-2.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3133_ofr20231027.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1980-5373-mr-2018-0921.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.5194_essd-8-663-2016.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.7554_elife.74937.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1021_acsomega.3c06074.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.5937_bnhmb1811227u.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13104-018-4014-1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1007_jhep11(2018)115.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41467-018-04041-x.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\XML\\10.7554_elife.29944.xml\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_hdy.2014.75.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_chem.202003167.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41597-022-01555-4.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1055_s-0039-1693681.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1073_pnas.1711872115.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12913-018-3333-1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1098_rspb.2015.2726.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1980-5918.032.ao27.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12918-015-0209-4.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41437-020-0318-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12859-018-2414-9.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s40170-020-00212-x.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41562-021-01247-w.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.7717_peerj.10452.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1039_c9sc02930c.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_s1677-5538.ibju.2019.0167.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.7554_eLife.63194.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s11689-019-9287-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1140_epjds_s13688-018-0132-1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1093_sysbio_syy011.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_1365-2664.13136.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3133_ofr20201035.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13617-019-0084-6.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13073-020-00727-4.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12862-019-1388-1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13059-019-1908-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12931-019-1001-6.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_ncomms11871.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.14379_iodp.proc.390393.208.2024.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s160053681103220x.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41598-024-56373-y.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1029_2021pa004379.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pcbi.1011828.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1039_c9ra06638a.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12864-019-6324-7.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_1365-2656.12501.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1007_s00382-012-1636-1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41558-022-01301-z.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41598-020-59839-x.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_2017jc013030.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_ece3.4466.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12866-015-0509-2.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_ejoc.202000139.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12870-018-1542-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1806-90882019000500004.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12859-018-2036-2.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.7554_elife.63455.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s2052252515023945.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1806-93042019000400002.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_ece3.9627.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_1365-2664.13446.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13068-018-1316-4.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_ece3.6303.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_0001-3765201920180768.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1016_j.ast.2022.107401.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3390_ijms12117360.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1016_j.jobe.2023.107105.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1039_d0sc01197e.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s2414314616000523.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1140_epjc_s10052-019-6583-0.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.12688_f1000research.11698.1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13750-020-0184-0.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0253228.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0159387.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_0104-4060.59642.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13007-019-0403-2.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1809-2950_19008627012020.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s1600536812027390.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12859-016-0922-z.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_hdy.2015.99.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s40657-020-00194-w.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13024-018-0266-4.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_1365-2435.13431.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1617_s11527-023-02260-3.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12860-020-00261-6.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1145_3461702.3462538.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_eva.12151.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13100-019-0153-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13068-018-1167-z.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12859-016-1206-3.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s1600536812046892.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1678-4499.20190067.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_1365-2656.12491.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1242_dev.138545.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_0102.3772e35417.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1130_ges01387.1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13104-019-4127-1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12915-018-0498-3.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.18438_eblip29674.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s40851-018-0089-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_sdata.2017.167.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3389_fchem.2019.00828.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_evo.13972.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_0047-2085000000239.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_ecs2.1280.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13568-018-0680-6.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1021_jacs.2c06519.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.12688_f1000research.13064.1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s40793-015-0095-9.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.17581_bp.2020.09104.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12866-019-1542-3.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_esp.5090.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_s1678-86212019000400340.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1016_j.dib.2023.109949.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13059-019-1924-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12870-020-2295-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_1365-2435.13087.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12920-019-0646-9.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1098_rsos.160417.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13148-019-0719-9.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1007_jhep12(2018)117.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1080_14756366.2020.1740692.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12859-020-3415-z.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12859-018-2263-6.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13643-018-0859-6.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1029_2018gl078007.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.5194_amt-15-3969-2022.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_esp.5058.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_ece3.961.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12879-019-3766-0.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1029_2023wr035126.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3897_neobiota.82.87455.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3389_fcimb.2024.1292467.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1039_d0sc01518k.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1519-6984.192126.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s40168-018-0550-0.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_ejoc.202000916.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12866-020-01863-y.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12885-018-4768-9.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0284951.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_chem.201903120.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1080_21645515.2023.2189598.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1016_j.jlp.2022.104761.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.5194_acp-2021-570.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12920-019-0611-7.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_ece3.6784.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3762_bjoc.8.42.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.12688_f1000research.4660.1.pdf\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for  annotations\n",
      "\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_anie.202007717.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3390_d13010019.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_fst.33717.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1029_2020jf005675.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1080_0284186x.2020.1714721.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13073-019-0674-2.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12885-020-06724-5.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1007_jhep11(2018)113.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3390_v11060565.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_2041-210x.13817.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_mp.14424.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1002_chem.202001412.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_1365-2664.13168.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3390_s19030479.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1080_02713683.2019.1607392.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1007_s12263-014-0408-4.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s2052252515011665.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.5194_essd-12-1287-2020.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1093_beheco_arad016.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1080_15476286.2016.1232238.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12885-018-4314-9.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_1365-2656.12382.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1140_epjc_s10052-018-6468-7.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1128_spectrum.00422-24.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s1600536810036299.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_eva.12768.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0188323.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1534_g3.119.400993.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1806-9479.2019.185555.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3897_zoologia.36.e32053.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13321-015-0110-6.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3389_fevo.2023.1112519.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s1600536809014883.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0139215.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_hdy.2013.74.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3847_1538-4357_aae92c.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s2414314616007033.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_cas.12935.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3897_zookeys.500.9360.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0262974.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12863-019-0790-4.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_eva.12446.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41598-017-15852-1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1080_0284186x.2019.1669817.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.7554_eLife.72626.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s1600536810047185.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1039_d0gc00363h.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s1600536812024269.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12864-019-6131-1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_0104-6632.20190362s20180340.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.5194_essd-2023-187.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41598-021-85671-y.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1073_pnas.1705601114.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s2056989020010658.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s2056989015019891.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_mec.16743.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12870-019-1889-5.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1038_s41467-018-07681-1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13068-018-1078-z.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12864-015-2206-9.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3897_zoologia.35.e23481.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1093_beheco_arw167.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.5194_acp-22-5701-2022.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13058-015-0618-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12881-019-0773-3.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.12688_f1000research.13483.1.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_2236-3459_83528.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.3897_bdj.7.e47369.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13024-018-0254-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0212669.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.5194_essd-2023-198.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1590_1980-5373-mr-2018-0766.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13073-019-0709-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s13071-018-3237-2.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1007_s10904-014-0054-8.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1111_gcb.13914.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s1600536807066780.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0137181.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12874-018-0583-x.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12943-019-1017-z.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12967-019-2100-3.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1029_2019pa003774.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1080_07350015.2020.1766469.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12903-018-0656-6.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1186_s12884-018-1751-z.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1371_journal.pone.0070749.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\train\\PDF\\10.1107_s1600536812014614.pdf\n",
      "Loaded training data for 324 articles.\n",
      "Prepared 324 training examples for the LLM.\n",
      "Training set size: 291 examples\n",
      "Validation set size: 33 examples\n"
     ]
    }
   ],
   "source": [
    "# This take 10+ minutes\n",
    "\n",
    "# 4.3. Populate ArticleData with DatasetCitation objects and ground truth\n",
    "training_data_for_llm = extract_training_data_for_llm(file_paths_df)\n",
    "print(f\"Prepared {len(training_data_for_llm)} training examples for the LLM.\")\n",
    "\n",
    "# Convert the list of LlmTrainingData to a DataFrame and save it\n",
    "training_data_for_llm_df = pd.DataFrame(training_data_for_llm)\n",
    "training_data_for_llm_df.to_csv(os.path.join(BASE_OUTPUT_DIR, \"training_data_for_llm.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f99b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 261 examples\n",
      "Validation set size: 29 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_of_string(s: str, length: int = 400) -> str:\n",
    "    return s[-length:]\n",
    "\n",
    "# Load data from the csv file\n",
    "training_data_for_llm_df = pd.read_csv(os.path.join(BASE_OUTPUT_DIR, \"training_data_for_llm.csv\"))\n",
    "training_data_for_llm_df = training_data_for_llm_df.sample(290, random_state=42)\n",
    "training_data_for_llm_df['citation_context'] = training_data_for_llm_df['citation_context'].apply(last_of_string)\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(training_data_for_llm_df)\n",
    "\n",
    "# Split into train/validation\n",
    "train_test_split = train_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "print(f\"Training set size: {len(train_dataset)} examples\")\n",
    "print(f\"Validation set size: {len(eval_dataset)} examples\")\n",
    "\n",
    "# Clean up\n",
    "del training_data_for_llm_df\n",
    "del train_test_split\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3726457c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 few-shot examples.\n",
      "New training set size: 277 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e557d60b5bb4c0cb816ed7bd70955f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720ba376265240d8b7376260654aa111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "19113"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the few-shot examples with the main training dataset\n",
    "# This will add the few-shot examples as additional rows to the training data\n",
    "few_shot_dataset = Dataset.from_csv(FEW_SHOT_CSV_PATH)\n",
    "print(f\"Loaded {len(few_shot_dataset)} few-shot examples.\")\n",
    "train_dataset = concatenate_datasets([train_dataset, few_shot_dataset])\n",
    "print(f\"New training set size: {len(train_dataset)} examples\")\n",
    "\n",
    "# Save off the datasets to CSV for later use\n",
    "train_dataset.to_csv(os.path.join(BASE_OUTPUT_DIR, \"train_dataset.csv\"), index=False)\n",
    "eval_dataset.to_csv(os.path.join(BASE_OUTPUT_DIR, \"eval_dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load datasets from CSV\n",
    "# train_dataset = Dataset.from_csv(os.path.join(BASE_OUTPUT_DIR, \"train_dataset.csv\"))\n",
    "# eval_dataset = Dataset.from_csv(os.path.join(BASE_OUTPUT_DIR, \"eval_dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b7ee0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article_id', 'article_doi', 'article_abstract', 'dataset_id', 'citation_context', 'label', '__index_level_0__'],\n",
       "    num_rows: 277\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ae25fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article_id', 'article_doi', 'article_abstract', 'dataset_id', 'citation_context', 'label', '__index_level_0__'],\n",
       "    num_rows: 29\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0066f50c",
   "metadata": {},
   "source": [
    "#### 5. Model Selection and Configuration\n",
    "\n",
    "We'll use a Qwen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12e2982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model C:\\Users\\jim\\.cache\\kagglehub\\models\\qwen-lm\\qwen-3\\transformers\\0.6b\\1 loaded with 4-bit quantization.\n"
     ]
    }
   ],
   "source": [
    "# 5.1. Choose a Model from KaggleHub\n",
    "# Example: Qwen/Qwen1.5-0.5B-Chat (or 1.8B-Chat if 0.5B is too small/performs poorly)\n",
    "# You can find these on KaggleHub or Hugging Face Hub.\n",
    "model_name = QWEN_BASE_MODEL_PATH\n",
    "\n",
    "# 5.2. Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token # Qwen uses EOS for padding\n",
    "\n",
    "# 5.3. Load Model with Quantization (4-bit)\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 # Or torch.float16 if bfloat16 is not supported by your GPU\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=nf4_config,\n",
    "    torch_dtype=torch.bfloat16, # Match compute_dtype\n",
    "    device_map=\"auto\", # Automatically maps model to available devices\n",
    "    trust_remote_code=True # Required for some models like Qwen\n",
    ")\n",
    "\n",
    "# Prepare model for k-bit training (LoRA compatible)\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "print(f\"Model {model_name} loaded with 4-bit quantization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83df8",
   "metadata": {},
   "source": [
    "#### 6. Dataset Preparation for Training\n",
    "\n",
    "Format the extracted data into instruction-tuning prompts using the ChatML format, which Qwen models are trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a008679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of formatted training data (string output):\n",
      "Length of the full prompt in tokens: 496\n",
      "<|im_start|>system\n",
      "You are an expert assistant for classifying research data citations. /no_think<|im_end|>\n",
      "<|im_start|>user\n",
      "\n",
      "Given the following 'Article Abstract' and a specific data citation ('Dataset ID' and 'Data Citation Context' combination), classify the data citation as either: \n",
      "'Primary' (if the data citation refers to raw or processed **data created/generated as part of the paper**, specifically for this study), \n",
      "'Secondary' (if the data citation refers to raw or processed **data derived/reused from existing records** or previously published data), or \n",
      "'Missing' (if the data citation refers to another **article/paper/journal**, a **figure, software, or other non-data entity**, or the 'Data Citation Context' is **empty or irrelevant**).\n",
      "\n",
      "If the data citation refers to raw or processed **data** but the distinction between 'Primary' and 'Secondary' is ambiguous, then default to 'Primary'.\n",
      "\n",
      "Now, classify the following:\n",
      "\n",
      "Article Abstract: The genome of a laboratory-adapted strain of Leptospira interrogans serovar Hardjo was sequenced and analyzed. Comparison of the sequenced genome with that recently pub lished for a field isolate of the same serovar revealed relatively high sequence conservation at the nucleotide level, despite the different biological background of both samples. Con versely, comparison of both serovar Hardjo geno\n",
      "Dataset ID: PRJNA74167\n",
      "Data Citation Context: RJNA74167 L. santarosai Shermani LT 821 LSS PRJNA47139 L. weilii --- UI 13098 LEP1GSC108 PRJNA74123 doi:10.1371/journal.pone.0159387.t001 PLOS ONE | DOI:10.1371/journal.pone.0159387 July 21, 2016 3 / 12 Phylogenomic Analysis of Leptospira interrogans Serovar Hardjo corresponding to chromosomes I (4.34 Mb) and II (353 kb), by using ABACAS and the genome of L. interrogans serovar Lai as a reference.\n",
      "\n",
      "Classification:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Secondary<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6.1. Define the formatting function for ChatML (Corrected for trl 0.19.1)\n",
    "def format_example(example):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert assistant for classifying research data citations. /no_think\"},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            f\"\"\"\n",
    "Given the following 'Article Abstract' and a specific data citation ('Dataset ID' and 'Data Citation Context' combination), classify the data citation as either: \n",
    "'Primary' (if the data citation refers to raw or processed **data created/generated as part of the paper**, specifically for this study), \n",
    "'Secondary' (if the data citation refers to raw or processed **data derived/reused from existing records** or previously published data), or \n",
    "'Missing' (if the data citation refers to another **article/paper/journal**, a **figure, software, or other non-data entity**, or the 'Data Citation Context' is **empty or irrelevant**).\\n\\n\"\"\"\n",
    "            f\"If the data citation refers to raw or processed **data** but the distinction between 'Primary' and 'Secondary' is ambiguous, then default to 'Primary'.\\n\\n\"\n",
    "            # f\"{FEW_SHOT_EXAMPLES.strip()}\\n\\n\" # Add the examples here\n",
    "            f\"Now, classify the following:\\n\\n\" # Add a clear separator            \n",
    "            f\"Article Abstract: {example['article_abstract']}\\n\" \n",
    "            f\"Dataset ID: {example['dataset_id']}\\n\"\n",
    "            f\"Data Citation Context: {example['citation_context']}\\n\\n\"\n",
    "            f\"Classification:\"\n",
    "        )}\n",
    "    ]\n",
    "    # The target output for the model is just \"Primary\", \"Secondary, or \"Missing\"\n",
    "    messages.append({\"role\": \"assistant\", \"content\": example['label']})\n",
    "    \n",
    "    # Apply chat template and return the string directly\n",
    "    # <--- IMPORTANT CHANGE: Directly return the string, not a dictionary\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False, enable_thinking=False)\n",
    "\n",
    "# Apply the formatting to the dataset\n",
    "# IMPORTANT: When formatting_func returns a string directly, you typically don't\n",
    "# need to call .map() on the dataset beforehand if SFTTrainer handles it internally.\n",
    "# However, if you want to inspect the formatted text, you can still do this:\n",
    "# formatted_train_dataset = train_dataset.map(format_example)\n",
    "# But for SFTTrainer, you pass the original `train_dataset` and the `formatting_func`\n",
    "# and `dataset_text_field` (which will be ignored if formatting_func is used to generate the text).\n",
    "\n",
    "# Print an example to verify (you'll need to call format_example directly for this)\n",
    "print(\"\\nExample of formatted training data (string output):\")\n",
    "# You can't directly print from formatted_train_dataset if you don't map it first.\n",
    "# Let's print by calling the function on a sample:\n",
    "if len(train_dataset) > 0:\n",
    "    sample_formatted_text = format_example(train_dataset[35])\n",
    "    tokenized_input = tokenizer(sample_formatted_text, return_tensors=\"pt\")\n",
    "    prompt_length = tokenized_input.input_ids.shape[1]\n",
    "    print(f\"Length of the full prompt in tokens: {prompt_length}\")    \n",
    "    print(sample_formatted_text)\n",
    "else:\n",
    "    print(\"No training data to display example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d74e3",
   "metadata": {},
   "source": [
    "### 7. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d8fdd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f886a0b7addf4492b2cb12f80a636ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a80cd0a235244a59b314895d0dc358d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bde8cd6c4c46ae82bf95124b9a6053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbed3abcc8e4906b169bce4e39e7fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0129f58e4c9746ed9654ff458123dab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to eval dataset:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6288bfa3d2894f8e87dd020993ad1ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01534cf4249d485a9ee33142513b661b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69daf00ac3747538915c452aa6eddd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# This version uses the evaluation dataset in the SFTTrainer\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers.trainer_utils import EvalPrediction # Import this for type hinting if desired\n",
    "\n",
    "# Assuming your model outputs logits for 3 classes (Primary, Secondary, Missing)\n",
    "# And your labels are integers (e.g., 0, 1, 2) corresponding to these classes.\n",
    "\n",
    "def compute_classification_metrics(eval_pred: EvalPrediction):\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    \n",
    "    # For classification, you typically take the argmax of the logits to get predicted class IDs\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Calculate desired metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1_macro = f1_score(labels, predictions, average='macro') # Macro F1 treats all classes equally\n",
    "    f1_weighted = f1_score(labels, predictions, average='weighted') # Weighted F1 accounts for class imbalance\n",
    "    \n",
    "    # You might also want precision and recall per class, or just overall\n",
    "    # precision_macro = precision_score(labels, predictions, average='macro')\n",
    "    # recall_macro = recall_score(labels, predictions, average='macro')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        # You can also include 'eval_loss' if you want, but Trainer computes it by default\n",
    "        # \"eval_loss\": eval_pred.metrics.get(\"eval_loss\", None) # Access it if Trainer provides it\n",
    "    }\n",
    "\n",
    "# 7.1. Configure LoRA\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=\"all-linear\", # Adjust based on model architecture if needed\n",
    ")\n",
    "\n",
    "# 7.2. Configure Training Arguments (now using SFTConfig)\n",
    "training_args = SFTConfig(\n",
    "    output_dir=FINE_TUNED_MODEL_OUTPUT_DIR,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_steps=25,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=['labels'],\n",
    "    \n",
    "    # SFTTrainer-specific parameters moved into SFTConfig\n",
    "    max_seq_length=512,\n",
    "    packing=False,\n",
    "    dataset_text_field=\"text\",\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':False},\n",
    "\n",
    "    # --- NEW: Evaluation Parameters ---\n",
    "    eval_strategy=\"steps\", # Evaluate every 'eval_steps'. You can also use \"epoch\" for evaluation_strategy\n",
    "    eval_steps=25,               # How often to run evaluation (e.g., every 25 steps)\n",
    "    save_strategy=\"steps\",       # How often to save checkpoints\n",
    "    save_total_limit=1,          # Only keep the best model checkpoint\n",
    "    load_best_model_at_end=True, # Load the model with the best validation metric at the end of training\n",
    "    greater_is_better=False,     # For loss, lower is better\n",
    ")\n",
    "\n",
    "# 7.3. Initialize SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset, # <--- Pass the evaluation dataset here\n",
    "    # compute_metrics=compute_classification_metrics,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args,\n",
    "    formatting_func=format_example\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45982673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/54 06:42 < 07:49, 0.06 it/s, Epoch 1.40/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.267800</td>\n",
       "      <td>1.078030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 7.4. Start Training\n",
    "print(\"\\nStarting model training...\")\n",
    "trainer.train()\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Save the fine-tuned model (LoRA adapters)\n",
    "trainer.save_model(os.path.join(FINE_TUNED_MODEL_OUTPUT_DIR, \"final_model\"))\n",
    "print(f\"Fine-tuned model saved to {os.path.join(FINE_TUNED_MODEL_OUTPUT_DIR, 'final_model')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce92dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initiating GPU memory cleanup...\n",
      "GPU memory cleanup complete. Please check nvidia-smi to confirm.\n"
     ]
    }
   ],
   "source": [
    "# --- Explicit GPU Memory Cleanup ---\n",
    "print(\"\\nInitiating GPU memory cleanup...\")\n",
    "\n",
    "# 1. Explicitly delete large objects that consume GPU memory\n",
    "#    This removes references, allowing Python's garbage collector to act.\n",
    "# if 'trainer' in locals() and trainer is not None:\n",
    "#     del trainer\n",
    "# if 'model' in locals() and model is not None:\n",
    "#     del model\n",
    "# if 'tokenizer' in locals() and tokenizer is not None:\n",
    "#     del tokenizer\n",
    "# If you had other large tensors or datasets explicitly moved to GPU,\n",
    "# you would delete them here too. For Hugging Face datasets, they are usually\n",
    "# on CPU unless you manually call .to('cuda').\n",
    "\n",
    "# 2. Force Python's garbage collection\n",
    "#    This helps ensure that deleted objects are immediately cleaned up.\n",
    "# gc.collect()\n",
    "\n",
    "# 3. Clear PyTorch's CUDA memory cache\n",
    "#    This tells PyTorch to release any cached memory back to the OS/driver.\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "print(\"GPU memory cleanup complete. Please check nvidia-smi to confirm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e3154",
   "metadata": {},
   "source": [
    "#### 8. Inference and Evaluation\n",
    "\n",
    "After training, load the best model (or the final one) and apply it to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "583fed9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded for inference.\n"
     ]
    }
   ],
   "source": [
    "# 8.1. Load the Trained Model (or merge LoRA adapters for full model)\n",
    "# If you saved LoRA adapters, you'll need to load the base model and then the adapters.\n",
    "# For inference, it's often easier to merge them.\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     quantization_config=nf4_config, # Use the same config as training\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "# model = PeftModel.from_pretrained(model, os.path.join(FINE_TUNED_MODEL_OUTPUT_DIR, \"final_model\"))\n",
    "# model = model.merge_and_unload() # Merge LoRA adapters into the base model\n",
    "\n",
    "# For simplicity, if you just want to test the last saved checkpoint:\n",
    "# You can also load the model directly from the checkpoint if it's a full save\n",
    "# model = AutoModelForCausalLM.from_pretrained(os.path.join(FINE_TUNED_MODEL_OUTPUT_DIR, \"final_model\"), device_map=\"auto\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(os.path.join(FINE_TUNED_MODEL_OUTPUT_DIR, \"final_model\"))\n",
    "\n",
    "# If you want to load the base model and then the adapters for inference:\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=nf4_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, os.path.join(FINE_TUNED_MODEL_OUTPUT_DIR, \"final_model\"))\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "print(\"Model loaded for inference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bc475f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files paths shape: (30, 4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "xml_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c60aaf83-ec3a-40f2-9abb-a58c8b7d6ffc",
       "rows": [
        [
         "27",
         "10.1002_mp.14424",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_mp.14424.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_mp.14424.xml",
         "test"
        ],
        [
         "15",
         "10.1002_ece3.6144",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.6144.pdf",
         "./kaggle/input/make-data-count-finding-data-references\\test\\XML\\10.1002_ece3.6144.xml",
         "test"
        ],
        [
         "23",
         "10.1002_ejoc.202000139",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ejoc.202000139.pdf",
         "",
         "test"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>pdf_file_path</th>\n",
       "      <th>xml_file_path</th>\n",
       "      <th>dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.1002_mp.14424</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.1002_ece3.6144</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.1002_ejoc.202000139</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td></td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                article_id                                      pdf_file_path  \\\n",
       "27        10.1002_mp.14424  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "15       10.1002_ece3.6144  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "23  10.1002_ejoc.202000139  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "\n",
       "                                        xml_file_path dataset_type  \n",
       "27  ./kaggle/input/make-data-count-finding-data-re...         test  \n",
       "15  ./kaggle/input/make-data-count-finding-data-re...         test  \n",
       "23                                                            test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For testing, always set to the TEST_DATA_DIR\n",
    "base_file_dir = TEST_DATA_DIR\n",
    "\n",
    "# Load file paths for base directory\n",
    "test_file_paths_df = load_file_paths(base_file_dir)\n",
    "test_file_paths_df['xml_file_path'] = test_file_paths_df['xml_file_path'].fillna('')\n",
    "\n",
    "print(f\"Files paths shape: {test_file_paths_df.shape}\")\n",
    "display(test_file_paths_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def invoke_model_for_inference(tokenizer, article_data: ArticleData) -> list[SubmissionData]:\n",
    "    submission_data_list = []\n",
    "    article_id = article_data.article_id\n",
    "    dataset_citations = article_data.dataset_citations\n",
    "    if not dataset_citations:\n",
    "        submission_data_list.append(SubmissionData(article_id, dataset_id=\"Missing\", type=\"Missing\"))\n",
    "        return submission_data_list\n",
    "\n",
    "    print(f\"Found {len(dataset_citations)} citations for {article_id}\")\n",
    "    for dc in dataset_citations:\n",
    "        # Create the prompt for inference\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert assistant for classifying research data citations. /no_think\"},\n",
    "            {\"role\": \"user\", \"content\": (\n",
    "                f\"\"\"\n",
    "Given the following 'Article Abstract' and a specific data citation ('Dataset ID' and 'Data Citation Context' combination), classify the data citation as either: \n",
    "'Primary' (if the data citation refers to raw or processed **data created/generated as part of the paper**, specifically for this study), \n",
    "'Secondary' (if the data citation refers to raw or processed **data derived/reused from existing records** or previously published data), or \n",
    "'Missing' (if the data citation refers to another **article/paper/journal**, a **figure, software, or other non-data entity**, or the 'Data Citation Context' is **empty or irrelevant**).\\n\\n\"\"\"\n",
    "                f\"If the data citation refers to raw or processed **data** but the distinction between 'Primary' and 'Secondary' is ambiguous, then default to 'Primary'.\\n\\n\"\n",
    "                # f\"{FEW_SHOT_EXAMPLES.strip()}\\n\\n\" # Add the examples here\n",
    "                f\"Now, classify the following:\\n\\n\" # Add a clear separator            \n",
    "                f\"Article Abstract: {article_data.abstract}\\n\"\n",
    "                f\"Dataset ID: {dc.dataset_id}\\n\"                \n",
    "                f\"Data Citation Context: {dc.citation_context}\\n\\n\"\n",
    "                f\"Classification:\"\n",
    "            )}\n",
    "        ]\n",
    "\n",
    "        # --- CHANGE STARTS HERE ---\n",
    "        # Tokenize and get both input_ids and attention_mask\n",
    "        input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs, # <--- Pass the entire dictionary (includes input_ids and attention_mask)\n",
    "                max_new_tokens=10, # Expecting \"Primary\" or \"Secondary\"\n",
    "                do_sample=True,    # <--- Enable sampling\n",
    "                temperature=0.7,   # <--- Adjust temperature (0.7-0.9 is common)\n",
    "                top_p=0.9,         # <--- Top-p sampling (consider tokens that sum to 90% probability)\n",
    "                top_k=50,          # <--- Top-k sampling (consider only the top 50 most probable tokens)                \n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        # --- CHANGE ENDS HERE ---        \n",
    "\n",
    "        generated_text = tokenizer.decode(output[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True).strip() # Use inputs['input_ids']\n",
    "        # print(f\"LLM Resp: {generated_text}\")        \n",
    "        \n",
    "        # Post-process the generated text to get the classification\n",
    "        predicted_type = \"Missing\"\n",
    "        if \"Primary\" in generated_text:\n",
    "            predicted_type = \"Primary\"\n",
    "        elif \"Secondary\" in generated_text:\n",
    "            predicted_type = \"Secondary\"\n",
    "        \n",
    "        submission_data_list.append(SubmissionData(article_id, dataset_id=dc.dataset_id, type=predicted_type, context=dc.citation_context))\n",
    "\n",
    "    return submission_data_list\n",
    "\n",
    "def process_test_articles(tokenizer, file_paths_df: pd.DataFrame) -> list[SubmissionData]:\n",
    "    \"\"\"\n",
    "    Extracts article data for testing set without ground truth.\n",
    "    \n",
    "    Args:\n",
    "        file_paths_df (pd.DataFrame): DataFrame containing file paths and ground truth info.\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, ArticleData]: Dictionary mapping article IDs to ArticleData objects.\n",
    "    \"\"\"\n",
    "    submission_data_list = []\n",
    "    for i, row in tqdm(file_paths_df.iterrows(), total=len(file_paths_df)):\n",
    "        article_id = row['article_id']\n",
    "        filepath = row['pdf_file_path'] if row['pdf_file_path'] else row['xml_file_path']\n",
    "        file_extractor = MdcFileTextExtractor(article_id, filepath)\n",
    "        \n",
    "        # Extract article data\n",
    "        article_data = file_extractor.extract_article_data_for_inference(NLP_SPACY)\n",
    "\n",
    "        # Invoke the model with the collected article_data\n",
    "        submission_data_list.extend(invoke_model_for_inference(tokenizer, article_data))\n",
    "\n",
    "    print(f\"Processed testing data for {len(submission_data_list)} article and dataset_id combos.\")\n",
    "    return submission_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "903dc0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "article_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdf_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "xml_file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "81d840bd-8a04-43e2-9138-998c09241cee",
       "rows": [
        [
         "20",
         "10.1002_ecs2.1280",
         "./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ecs2.1280.pdf",
         "",
         "test"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>pdf_file_path</th>\n",
       "      <th>xml_file_path</th>\n",
       "      <th>dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.1002_ecs2.1280</td>\n",
       "      <td>./kaggle/input/make-data-count-finding-data-re...</td>\n",
       "      <td></td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           article_id                                      pdf_file_path  \\\n",
       "20  10.1002_ecs2.1280  ./kaggle/input/make-data-count-finding-data-re...   \n",
       "\n",
       "   xml_file_path dataset_type  \n",
       "20                       test  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_file_paths_df = test_file_paths_df.sample(2, random_state=42)\n",
    "sample_test_file_paths_df = test_file_paths_df.loc[test_file_paths_df['article_id']=='10.1002_mp.14424']\n",
    "sample_test_file_paths_df = test_file_paths_df.loc[test_file_paths_df['article_id']=='10.1002_cssc.202201821']\n",
    "sample_test_file_paths_df = test_file_paths_df.loc[test_file_paths_df['article_id']=='10.1002_ecs2.1280']\n",
    "# sample_test_file_paths_df = test_file_paths_df.loc[test_file_paths_df['article_id']=='10.1002_esp.5090']\n",
    "sample_test_file_paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efde80b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23153ae59b0f4509a1e5442a9df008de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_2017jc013030.pdf\n",
      "Found 2 citations for 10.1002_2017jc013030\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_anie.201916483.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_anie.202005531.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_anie.202007717.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.201902131.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.201903120.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.202000235.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.202001412.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.202001668.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_chem.202003167.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_cssc.202201821.pdf\n",
      "Found 1 citations for 10.1002_cssc.202201821\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.3985.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.4466.pdf\n",
      "Found 1 citations for 10.1002_ece3.4466\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.5260.pdf\n",
      "Found 3 citations for 10.1002_ece3.5260\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.5395.pdf\n",
      "Found 5 citations for 10.1002_ece3.5395\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.6144.pdf\n",
      "Found 2 citations for 10.1002_ece3.6144\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.6303.pdf\n",
      "Found 5 citations for 10.1002_ece3.6303\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.6784.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.961.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ece3.9627.pdf\n",
      "Found 3 citations for 10.1002_ece3.9627\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ecs2.1280.pdf\n",
      "Found 1 citations for 10.1002_ecs2.1280\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ecs2.4619.pdf\n",
      "Found 1 citations for 10.1002_ecs2.4619\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ejic.201900904.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ejoc.202000139.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_ejoc.202000916.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_esp.5058.pdf\n",
      "Found 3 citations for 10.1002_esp.5058\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_esp.5090.pdf\n",
      "Found 1 citations for 10.1002_esp.5090\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_mp.14424.pdf\n",
      "Found 2 citations for 10.1002_mp.14424\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1002_nafm.10870.pdf\n",
      "Extracting md text from file: ./kaggle/input/make-data-count-finding-data-references\\test\\PDF\\10.1007_jhep07(2018)134.pdf\n",
      "Processed testing data for 47 article and dataset_id combos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SubmissionData(article_id='10.1002_2017jc013030', dataset_id='10.17882/49388', type='Secondary', context='Data referring to Organelli et al. (2016a; https://doi.org/10.17882/(https://doi.org/10.17882/47142) 47142) and Barbieux et al. (2017;(https://doi.org/10.17882/47142) https://doi.org/10.17882/49388) are(https://doi.org/10.17882/49388) freely available on SEANOE.'),\n",
       " SubmissionData(article_id='10.1002_2017jc013030', dataset_id='10.17882/47142', type='Primary', context='Approches Num�eriques); Pierre-Marie Poulain (National Institute of Oceanography and Experimental Geophysics, Italy; ArgoItaly); Sabrina Speich (Laboratoire de M�et�eorologie Dynamique, France; LEFEGMMC); Virginie Thierry (Ifremer, France; LEFE-GMMC); Pascal Conan (Observatoire Oc�eanologique de Banyuls sur mer, France; LEFE-GMMC); Laurent Coppola (Laboratoire d’Oc�eanographie de Villefranche, France; LEFE-GMMC); Anne Petrenko (Mediterranean Institute of Oceanography, France; LEFE-GMMC); and Jean-Baptiste Sall�ee (Laboratoire d’Oc�eanographie et du Climat, France; LEFE-GMMC). Collin Roesler (Bowdoin College, USA) and Yannick Huot (University of Sherbrooke, Canada) are acknowledged for useful comments and fruitful discussion. We also thank the International Argo Program and the CORIOLIS project that contribute to make the data freely and publicly available. Data referring to Organelli et al. (2016a; https://doi.org/10.17882/(https://doi.org/10.17882/47142)'),\n",
       " SubmissionData(article_id='10.1002_anie.201916483', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_anie.202005531', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_anie.202007717', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_chem.201902131', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_chem.201903120', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_chem.202000235', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_chem.202001412', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_chem.202001668', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_chem.202003167', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_cssc.202201821', dataset_id='10.5281/zenodo.7074790', type='Primary', context='*Conflict of Interest**_ The authors declare no conflict of interest. **Data Availability Statement** The data that support the findings of this study are openly available in zenodo at https://doi.org/10.5281/zenodo.7074790.(https://doi.org/10.5281/zenodo.7074790)'),\n",
       " SubmissionData(article_id='10.1002_ece3.3985', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_ece3.4466', dataset_id='10.5061/dryad.r6nq870', type='Secondary', context='**AUTHOR CONTRIBUTIONS** AH and MO conceived the ideas and designed methodology; AH col lected the data; AH and MO analyzed the data; AH led the writing **9832** HANSSON and OLSSON **|** of the manuscript. All authors contributed critically to the drafts and gave final approval for publication. **DATA ACCESSIBILITY** The dataset supporting this article are available in Dryad https://doi.(https://doi.org/10.5061/dryad.r6nq870)'),\n",
       " SubmissionData(article_id='10.1002_ece3.5260', dataset_id='MK838494', type='Secondary', context='J.S.S., J.M.P., and D.R.M. ob- tained and provided the Illumina and Sanger sequence data, assem- bled the base genomes, and produced genomic assembly metrics. All authors contributed to writing of the manuscript. **DATA AVAILABILITY** DNA sequences: GenBank MK838494 to MK838511; P(info:x-wiley/peptideatlas/MK838494) hyluce BED/ BAM files for probe design experiments and Adephaga_2.9Kv1 final probe set fasta file: Dryad https://doi.org/10.5061/dryad.2f62927;(https://doi.org/10.5061/dryad.2f62927)'),\n",
       " SubmissionData(article_id='10.1002_ece3.5260', dataset_id='10.5061/dryad.2f62927', type='Secondary', context='J.S.S., J.M.P., and D.R.M. ob- tained and provided the Illumina and Sanger sequence data, assem- bled the base genomes, and produced genomic assembly metrics. All authors contributed to writing of the manuscript. **DATA AVAILABILITY** DNA sequences: GenBank MK838494 to MK838511; P(info:x-wiley/peptideatlas/MK838494) hyluce BED/ BAM files for probe design experiments and Adephaga_2.9Kv1 final probe set fasta file: Dryad https://doi.org/10.5061/dryad.2f62927;(https://doi.org/10.5061/dryad.2f62927)'),\n",
       " SubmissionData(article_id='10.1002_ece3.5260', dataset_id='MK838511', type='Secondary', context='J.S.S., J.M.P., and D.R.M. ob- tained and provided the Illumina and Sanger sequence data, assem- bled the base genomes, and produced genomic assembly metrics. All authors contributed to writing of the manuscript. **DATA AVAILABILITY** DNA sequences: GenBank MK838494 to MK838511; P(info:x-wiley/peptideatlas/MK838494) hyluce BED/ BAM files for probe design experiments and Adephaga_2.9Kv1 final probe set fasta file: Dryad https://doi.org/10.5061/dryad.2f62927;(https://doi.org/10.5061/dryad.2f62927)'),\n",
       " SubmissionData(article_id='10.1002_ece3.5395', dataset_id='10.5441/001/1', type='Secondary', context='**DATA ACCESSIBILITY** The data used for this study are available through the Movebank Data Repository (https://www.movebank.org): with https://doi.org/10.5441(https://www.movebank.org) /001/1.v1cs4nn0, https://doi.org/10.5441/001/1.c42j3js7, https://(https://doi.org/10.5441/001/1.v1cs4nn0)'),\n",
       " SubmissionData(article_id='10.1002_ece3.5395', dataset_id='10.5441/001/1.c42j3js7', type='Secondary', context='**DATA ACCESSIBILITY** The data used for this study are available through the Movebank Data Repository (https://www.movebank.org): with https://doi.org/10.5441(https://www.movebank.org) /001/1.v1cs4nn0, https://doi.org/10.5441/001/1.c42j3js7, https://(https://doi.org/10.5441/001/1.v1cs4nn0)'),\n",
       " SubmissionData(article_id='10.1002_ece3.5395', dataset_id='10.5441/001/1.4192t2j4', type='Secondary', context='The data used for this study are available through the Movebank Data Repository (https://www.movebank.org): with https://doi.org/10.5441(https://www.movebank.org) /001/1.v1cs4nn0, https://doi.org/10.5441/001/1.c42j3js7, https://(https://doi.org/10.5441/001/1.v1cs4nn0) doi.org/10.5441/001/1.4192t2j4,(https://doi.org/10.5441/001/1.4192t2j4) https://doi.org/10.5441/001/1.(https://doi.org/10.5441/001/1.ck04mn78)'),\n",
       " SubmissionData(article_id='10.1002_ece3.5395', dataset_id='10.5441/001/1.v1cs4nn0', type='Secondary', context='**DATA ACCESSIBILITY** The data used for this study are available through the Movebank Data Repository (https://www.movebank.org): with https://doi.org/10.5441(https://www.movebank.org) /001/1.v1cs4nn0, https://doi.org/10.5441/001/1.c42j3js7, https://(https://doi.org/10.5441/001/1.v1cs4nn0)'),\n",
       " SubmissionData(article_id='10.1002_ece3.5395', dataset_id='10.5441/001/1.ck04mn78', type='Secondary', context='The data used for this study are available through the Movebank Data Repository (https://www.movebank.org): with https://doi.org/10.5441(https://www.movebank.org) /001/1.v1cs4nn0, https://doi.org/10.5441/001/1.c42j3js7, https://(https://doi.org/10.5441/001/1.v1cs4nn0) doi.org/10.5441/001/1.4192t2j4,(https://doi.org/10.5441/001/1.4192t2j4) https://doi.org/10.5441/001/1.(https://doi.org/10.5441/001/1.ck04mn78)'),\n",
       " SubmissionData(article_id='10.1002_ece3.6144', dataset_id='10.5061/dryad.zw3r22854', type='Secondary', context='Elena Duke performed research, analyzed data, and wrote the paper. Ron Burton designed research, wrote the paper, and is the principal investigator. **DATA AVAILABILITY STATEMENT** Data are available at Dryad Digital Repository at: https://doi.(https://doi.org/10.5061/dryad.zw3r22854)'),\n",
       " SubmissionData(article_id='10.1002_ece3.6144', dataset_id='MH718435', type='Secondary', context='Two species ( _Seriphus politus_ and _Etrumeus acuminatus_ ) included in our constructed libraries did not have 16S rRNA sequences in NCBI. We obtained tissue samples from voucher specimens for these species from the Scripps Institution of Oceanography Marine Vertebrate Collection, extracted and sequenced their DNA and submitted these sequences to GenBank (accession numbers: MH714866 and(info:ddbj-embl-genbank/MH714866) MH718435). The total number of reads per species was mapped and(info:ddbj-embl-genbank/MH718435) counted using RNA-seq analysis tools in CLC at 97% similarity to a local reference database.'),\n",
       " SubmissionData(article_id='10.1002_ece3.6303', dataset_id='MN335287', type='Secondary', context='The congener was collected from Kuocangshan Mountain in Linhai City, Zhejiang Province, China, and identified by Prof. Ming Jiang in Taizhou University, China. All phylogenetic analyses were performed with MEGA v 10.0.5 (Kumar et al., 2018). Sequences of the 34 haplotypes and the two outgroups have been **5622** WAN et al . **|** submitted to the National Center for Biotechnology Information (NCBI) database (accession numbers: MN107084-MN107151, MN335287-MN335290).'),\n",
       " SubmissionData(article_id='10.1002_ece3.6303', dataset_id='MN335290', type='Secondary', context='The congener was collected from Kuocangshan Mountain in Linhai City, Zhejiang Province, China, and identified by Prof. Ming Jiang in Taizhou University, China. All phylogenetic analyses were performed with MEGA v 10.0.5 (Kumar et al., 2018). Sequences of the 34 haplotypes and the two outgroups have been **5622** WAN et al . **|** submitted to the National Center for Biotechnology Information (NCBI) database (accession numbers: MN107084-MN107151, MN335287-MN335290).'),\n",
       " SubmissionData(article_id='10.1002_ece3.6303', dataset_id='10.5061/dryad.37pvmcvgb', type='Primary', context='**Feihai Yu:** Conceptualization (supporting); Writing-review & editing (supporting). **Junmin Li:** Conceptualization (lead); Funding acquisition (lead); Investigation (lead); Methodology (lead); Project administration (lead); Validation (lead); Writing-original draft (lead); Writing-review & editing (lead). **DATA AVAILABILITY STATEMENT** DNA sequences have been deposited in the National Center for Biotechnology Information (NCBI) database (accession numbers: MN107084-MN107151, MN335287-MN335290). The data that(info:ddbj-embl-genbank/MN107084) support the findings of this study have been deposited in Dryad with doi:https://doi.org/10.5061/dryad.37pvmcvgb.(https://doi.org/10.5061/dryad.37pvmcvgb) **ORCID** _'),\n",
       " SubmissionData(article_id='10.1002_ece3.6303', dataset_id='MN107084', type='Secondary', context='The congener was collected from Kuocangshan Mountain in Linhai City, Zhejiang Province, China, and identified by Prof. Ming Jiang in Taizhou University, China. All phylogenetic analyses were performed with MEGA v 10.0.5 (Kumar et al., 2018). Sequences of the 34 haplotypes and the two outgroups have been **5622** WAN et al . **|** submitted to the National Center for Biotechnology Information (NCBI) database (accession numbers: MN107084-MN107151, MN335287-MN335290).'),\n",
       " SubmissionData(article_id='10.1002_ece3.6303', dataset_id='MN107151', type='Secondary', context='The congener was collected from Kuocangshan Mountain in Linhai City, Zhejiang Province, China, and identified by Prof. Ming Jiang in Taizhou University, China. All phylogenetic analyses were performed with MEGA v 10.0.5 (Kumar et al., 2018). Sequences of the 34 haplotypes and the two outgroups have been **5622** WAN et al . **|** submitted to the National Center for Biotechnology Information (NCBI) database (accession numbers: MN107084-MN107151, MN335287-MN335290).'),\n",
       " SubmissionData(article_id='10.1002_ece3.6784', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_ece3.961', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_ece3.9627', dataset_id='10.6084/m9.figshare.21619055', type='Secondary', context='This article has earned Open Data and Open Materials badges. Data and materials are available at https://doi.org/10.5061/dryad.(https://doi.org/10.5061/dryad.b8gtht7h3) b8gtht7h3.(https://doi.org/10.5061/dryad.b8gtht7h3) **DATA AVAILABILITY STATEMENT** All R code and data used to implement our Bayesian co-\\xadabundance models can be accessed at this Figshare repository: https://doi.(https://doi.org/10.6084/m9.figshare.21619055)'),\n",
       " SubmissionData(article_id='10.1002_ece3.9627', dataset_id='10.5061/dryad', type='Secondary', context='** This article has earned Open Data and Open Materials badges. Data and materials are available at https://doi.org/10.5061/dryad.(https://doi.org/10.5061/dryad.b8gtht7h3) b8gtht7h3.(https://doi.org/10.5061/dryad.b8gtht7h3) **DATA AVAILABILITY STATEMENT**'),\n",
       " SubmissionData(article_id='10.1002_ece3.9627', dataset_id='10.5061/dryad.b8gtht7h3', type='Secondary', context='** This article has earned Open Data and Open Materials badges. Data and materials are available at https://doi.org/10.5061/dryad.(https://doi.org/10.5061/dryad.b8gtht7h3) b8gtht7h3.(https://doi.org/10.5061/dryad.b8gtht7h3) **DATA AVAILABILITY STATEMENT**'),\n",
       " SubmissionData(article_id='10.1002_ecs2.1280', dataset_id='10.5061/dryad.p3fg9', type='Secondary', context='Additional Supporting Information may be found online at: http://onlinelibrary.wiley.com/doi/10.1002/(http://onlinelibrary.wiley.com/doi/10.1002/ecs2.1280/supinfo) ecs2.1280/supinfo(http://onlinelibrary.wiley.com/doi/10.1002/ecs2.1280/supinfo) ## D ata A vailability Data associated with this paper have been deposited in Dryad: https://doi.org/10.5061/dryad.p3fg9(https://doi.org/10.5061/dryad.p3fg9) v www.esajournals.org 17 May 2016 v Volume 7(5) v'),\n",
       " SubmissionData(article_id='10.1002_ecs2.4619', dataset_id='10.25349/D9QW5X', type='Primary', context='The manuscript was greatly improved thanks to the attention and edits of John Melack, Tom Smith, and Jennifer King. CONFLICT OF INTEREST STATEMENT The authors declare no conflicts of interest. DATA AVAILABILITY STATEMENT Data and novel code (Owens et al., 2023) are available from Dryad: https://doi.org/10.25349/D9QW5X.(https://doi.org/10.25349/D9QW5X) ORCID'),\n",
       " SubmissionData(article_id='10.1002_ejic.201900904', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_ejoc.202000139', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_ejoc.202000916', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1002_esp.5058', dataset_id='10.5066/P9FW6E8K', type='Primary', context='Any use of trade, firm, or product names is for descriptive pur poses only and does not imply endorsement by the U.S. Government. CONFLICT OF INTEREST There is no conflict of interest in this paper. DATA AVAILABILITY STATEMENT The dataset of the bathymetric survey and structure from motion of the Ichilo River is openly available USGS data release at http://doi.(http://doi.org/10.5066/P9FW6E8K)'),\n",
       " SubmissionData(article_id='10.1002_esp.5058', dataset_id='10.5061/dryad', type='Secondary', context='CONFLICT OF INTEREST There is no conflict of interest in this paper. DATA AVAILABILITY STATEMENT The dataset of the bathymetric survey and structure from motion of the Ichilo River is openly available USGS data release at http://doi.(http://doi.org/10.5066/P9FW6E8K) org/10.5066/P9FW6E8K and Dryad https://doi.org/10.5061/dryad.(http://doi.org/10.5066/P9FW6E8K)'),\n",
       " SubmissionData(article_id='10.1002_esp.5058', dataset_id='10.5061/dryad.jh9w0vt9t', type='Secondary', context='DATA AVAILABILITY STATEMENT The dataset of the bathymetric survey and structure from motion of the Ichilo River is openly available USGS data release at http://doi.(http://doi.org/10.5066/P9FW6E8K) org/10.5066/P9FW6E8K and Dryad https://doi.org/10.5061/dryad.(http://doi.org/10.5066/P9FW6E8K) jh9w0vt9t, respectively.(https://doi.org/10.5061/dryad.jh9w0vt9t) ORCID Kattia Rubi Arnez Ferrel https://orcid.org/0000-0003-1670-3272(https://orcid.org/0000-0003-1670-3272) Jonathan Mark Nelson'),\n",
       " SubmissionData(article_id='10.1002_esp.5090', dataset_id='10.5066/P9353101', type='Secondary', context='2 | METHODS 2.1 | Analysis of Worldview-1 imagery and elevation model For our topographic analysis we use the pre- and post-Petermann earthquake digital elevation models (DEMs) produced by Gold et al. (2019). These were derived using pre-event (March and June 2014) and post-event (October and November 2016) in-track stereo 0.5 m resolution panchromatic WorldView-1 and WorldView-2 images (©2019, DigitalGlobe) using the Surface Extraction from TIN-based Searchspace Minimization software (Noh & Howat, 2015) running on the University of Iowa Argon supercomputer. The DEMs are available at https://doi.org/10.5066/P9353101, and the processing techniques(https://doi.org/10.5066/P9353101) are described in the supplementary information provided by Gold'),\n",
       " SubmissionData(article_id='10.1002_mp.14424', dataset_id='10.7937/tcia.2020.6c7y-gq39', type='Secondary', context='Four hundred and two thoracic segmentations were first generated automatically by a U-Net based algorithm trained on chest CTs without cancer, manually corrected by a medical student to include the complete thoracic cavity (normal, pathologic, and atelectatic lung parenchyma, lung hilum, pleural effusion, fibrosis, nodules, tumor, and other anatomic anomalies), and revised by a radiation oncologist or a radiologist. Seventy-eight pleural effusions were manually segmented by a medical student and revised by a radiologist or radiation oncologist. Interobserver agreement between the radiation oncologist and radiologist corrections was acceptable. All expert-vetted segmentations are publicly available in NIfTI format through The Cancer Imaging Archive at https://doi.org/10.7937/tcia.2020.6c7y-gq39.'),\n",
       " SubmissionData(article_id='10.1002_mp.14424', dataset_id='10.7937/K9/TCIA.2015.PF0M9REI', type='Primary', context='22. Aerts HJWL, Wee L, Rios Velazquez E, et al. Data from NSCLC-Radiomics Dataset. In: The Cancer Imaging Archive; 2019. https://doi.org/(https://doi.org/10.7937/K9/TCIA.2015.PF0M9REI)'),\n",
       " SubmissionData(article_id='10.1002_nafm.10870', dataset_id='Missing', type='Missing', context=''),\n",
       " SubmissionData(article_id='10.1007_jhep07(2018)134', dataset_id='Missing', type='Missing', context='')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_sub = process_test_articles(tokenizer, test_file_paths_df)\n",
    "display(sample_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef4754",
   "metadata": {},
   "source": [
    "#### 9. Submission File Generation (Kaggle Specific)\n",
    "\n",
    "Finally, format your predictions into the required `submission.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3aac269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset_id(dataset_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Formats the dataset_id by removing any leading/trailing whitespace and ensuring it is a string.\n",
    "    \n",
    "    Args:\n",
    "        dataset_id (str): The dataset identifier to format.\n",
    "        \n",
    "    Returns:\n",
    "        str: The formatted dataset identifier.\n",
    "    \"\"\"\n",
    "    if dataset_id and dataset_id.startswith(\"10.\") and len(dataset_id) > 10:\n",
    "        # If the dataset_id starts with \"10.\" and is longer than 10 characters, it's likely a DOI\n",
    "        dataset_id = \"https://doi.org/\" + dataset_id.lower().strip()\n",
    "    return dataset_id\n",
    "\n",
    "def prepare_for_submission(submission_list: list[SubmissionData]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares the submission_list for submission by ensuring the correct columns and formatting.\n",
    "    \n",
    "    Args:\n",
    "        expanded_df (pd.DataFrame): The DataFrame containing expanded dataset information.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame ready for submission with 'article_id', 'dataset_id', and 'type' columns.\n",
    "    \"\"\"\n",
    "    submission_df = pd.DataFrame(sample_sub)\n",
    "    # Ensure the DataFrame has the correct columns\n",
    "    submission_df = submission_df[['article_id', 'dataset_id', 'type']].copy()\n",
    "\n",
    "    # Format dataset_id\n",
    "    submission_df['dataset_id'] = submission_df['dataset_id'].apply(format_dataset_id)  \n",
    "\n",
    "    # Remove rows where type is 'Missing' and reset index\n",
    "    submission_df = submission_df[submission_df['type'] != 'Missing'].reset_index(drop=True)\n",
    "    submission_df['row_id'] = range(len(submission_df))\n",
    "\n",
    "    # Reorder columns to match the submission format\n",
    "    submission_df = submission_df[['row_id', 'article_id', 'dataset_id', 'type']]\n",
    "    \n",
    "    return submission_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission_df.csv' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# 9.1. Create Submission DataFrame\n",
    "\n",
    "submission_df = prepare_for_submission(sample_sub)\n",
    "submission_df.to_csv(\"submission_df.csv\", index=False)\n",
    "print(\"Submission file 'submission_df.csv' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf893421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 4\n",
      "FP: 26\n",
      "FN: 10\n",
      "F1 Score: 0.182\n"
     ]
    }
   ],
   "source": [
    "def f1_score(tp, fp, fn):\n",
    "    return 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 0.0\n",
    "    \n",
    "    \n",
    "# if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "pred_df = submission_df.copy()\n",
    "label_df = pd.read_csv(\"./kaggle/input/make-data-count-finding-data-references/sample_submission.csv\")\n",
    "label_df = label_df[label_df['type'] != 'Missing'].reset_index(drop=True)\n",
    "\n",
    "hits_df = label_df.merge(pred_df, on=[\"article_id\", \"dataset_id\", \"type\"])\n",
    "\n",
    "tp = hits_df.shape[0]\n",
    "fp = pred_df.shape[0] - tp\n",
    "fn = label_df.shape[0] - tp\n",
    "\n",
    "\n",
    "print(\"TP:\", tp)\n",
    "print(\"FP:\", fp)\n",
    "print(\"FN:\", fn)\n",
    "print(\"F1 Score:\", round(f1_score(tp, fp, fn), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
