{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b5173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError\n",
    "\n",
    "# --- Mock PDF Processing Functions (from previous example) ---\n",
    "def _read_pdf_to_markdown(pdf_filepath):\n",
    "    base_name = os.path.basename(pdf_filepath)\n",
    "    if \"article_5\" in base_name:\n",
    "        print(f\"  [Markdown Converter] Simulating long Markdown conversion for {base_name}...\")\n",
    "        time.sleep(1.2) # Simulate a 5-second conversion\n",
    "        return f\"# Markdown Content for {base_name}\\n\\nThis is a simulated long markdown conversion result.\"\n",
    "    else:\n",
    "        time.sleep(0.2) # Simulate a 0.5-second conversion for others\n",
    "        return f\"# Markdown Content for {base_name}\\n\\nThis is the simulated markdown content.\"\n",
    "\n",
    "def _read_pdf_plain_text(pdf_filepath):\n",
    "    base_name = os.path.basename(pdf_filepath)\n",
    "    time.sleep(0.1) # Simulate a quick read\n",
    "    return f\"Plain Text Content for {base_name}. This is the fallback text.\"\n",
    "\n",
    "# --- New Mock XML Processing Function ---\n",
    "def _read_xml_file(xml_filepath):\n",
    "    \"\"\"\n",
    "    Mocks XML file processing.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(xml_filepath)\n",
    "    time.sleep(0.1) # Simulate some XML parsing time\n",
    "    # In a real scenario, you'd use lxml or xml.etree.ElementTree\n",
    "    # to parse the XML and extract relevant data.\n",
    "    return f\"<processed_xml><file>{base_name}</file><data>Extracted data from XML.</data></processed_xml>\"\n",
    "\n",
    "# --- File Specific Processing Task Functions ---\n",
    "\n",
    "def _process_pdf_task(pdf_filepath, markdown_timeout_seconds):\n",
    "    \"\"\"\n",
    "    Encapsulates the PDF processing logic (Markdown with timeout, fallback to plain text).\n",
    "    Returns content and metadata about the processing.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(pdf_filepath)\n",
    "    markdown_content = None\n",
    "    status = \"success\"\n",
    "    message = \"Processed with Markdown\"\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1) as markdown_executor:\n",
    "        markdown_future = markdown_executor.submit(_read_pdf_to_markdown, pdf_filepath)\n",
    "        try:\n",
    "            markdown_content = markdown_future.result(timeout=markdown_timeout_seconds)\n",
    "            print(f\"  [PDF Logic] Markdown conversion successful for {base_name}.\")\n",
    "        except TimeoutError:\n",
    "            print(f\"  [PDF Logic] Timeout: Markdown conversion for {base_name} took too long ({markdown_timeout_seconds}s). Falling back to plain text.\")\n",
    "            status = \"timeout_fallback\"\n",
    "            message = \"Markdown conversion timed out, fell back to plain text\"\n",
    "        except Exception as e:\n",
    "            print(f\"  [PDF Logic] Error during Markdown conversion for {base_name}: {e}. Falling back to plain text.\")\n",
    "            status = \"error_fallback\"\n",
    "            message = f\"Markdown conversion failed: {e}, fell back to plain text\"\n",
    "\n",
    "    if markdown_content is None:\n",
    "        try:\n",
    "            final_content = _read_pdf_plain_text(pdf_filepath)\n",
    "            print(f\"  [PDF Logic] Successfully read plain text for {base_name}.\")\n",
    "            content_type = \"plain_text\"\n",
    "        except Exception as e:\n",
    "            print(f\"  [PDF Logic] Critical Error: Could not read plain text for {base_name}: {e}.\")\n",
    "            status = \"critical_error\"\n",
    "            message = f\"Failed to read plain text: {e}\"\n",
    "            final_content = \"Error: Could not process file.\"\n",
    "            content_type = \"error\"\n",
    "    else:\n",
    "        final_content = markdown_content\n",
    "        content_type = \"markdown\"\n",
    "\n",
    "    return {\n",
    "        \"content\": final_content,\n",
    "        \"status\": status,\n",
    "        \"message\": message,\n",
    "        \"content_type\": content_type\n",
    "    }\n",
    "\n",
    "def _process_xml_task(xml_filepath):\n",
    "    \"\"\"\n",
    "    Encapsulates the XML processing logic.\n",
    "    Returns content and metadata about the processing.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(xml_filepath)\n",
    "    print(f\"  [XML Logic] Processing XML file: {base_name}...\")\n",
    "    try:\n",
    "        processed_xml_content = _read_xml_file(xml_filepath)\n",
    "        status = \"success\"\n",
    "        message = \"Processed XML content\"\n",
    "        content_type = \"xml\"\n",
    "    except Exception as e:\n",
    "        print(f\"  [XML Logic] Error processing XML for {base_name}: {e}.\")\n",
    "        processed_xml_content = f\"Error processing XML: {e}\"\n",
    "        status = \"error\"\n",
    "        message = f\"XML processing failed: {e}\"\n",
    "        content_type = \"error\"\n",
    "\n",
    "    return {\n",
    "        \"content\": processed_xml_content,\n",
    "        \"status\": status,\n",
    "        \"message\": message,\n",
    "        \"content_type\": content_type\n",
    "    }\n",
    "\n",
    "# --- Generic Worker Function (submitted to ThreadPoolExecutor) ---\n",
    "def _generic_file_worker(filepath, output_dir, processing_task_func, **logic_kwargs):\n",
    "    \"\"\"\n",
    "    Generic worker function that calls a specific processing logic function\n",
    "    and handles saving the results.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(filepath)\n",
    "    print(f\"Processing {base_name} using {processing_task_func.__name__}...\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Call the specific processing logic function\n",
    "        logic_result = processing_task_func(filepath, **logic_kwargs)\n",
    "        \n",
    "        # Extract results from the logic function\n",
    "        final_content = logic_result.get(\"content\", \"No content\")\n",
    "        status = logic_result.get(\"status\", \"unknown\")\n",
    "        message = logic_result.get(\"message\", \"No message\")\n",
    "        content_type = logic_result.get(\"content_type\", \"unknown\")\n",
    "\n",
    "        processed_data = {\n",
    "            \"filename\": base_name,\n",
    "            \"status\": status,\n",
    "            \"message\": message,\n",
    "            \"content_type\": content_type,\n",
    "            \"processed_chars\": len(final_content)\n",
    "        }\n",
    "        \n",
    "        # Save the result\n",
    "        output_filepath = os.path.join(output_dir, base_name + \".json\")\n",
    "        with open(output_filepath, 'w', encoding='utf-8') as f_out:\n",
    "            json.dump(processed_data, f_out, indent=2)\n",
    "        print(f\"  [Generic Worker] Saved result for {base_name}.\")\n",
    "        return {\"filepath\": filepath, \"status\": status, \"data\": processed_data}\n",
    "    except Exception as e:\n",
    "        print(f\"  [Generic Worker] Error processing or saving result for {base_name}: {e}\")\n",
    "        return {\"filepath\": filepath, \"status\": \"worker_error\", \"message\": str(e)}\n",
    "\n",
    "# --- Concurrent File Processor Class ---\n",
    "class ConcurrentFileProcessor:\n",
    "    def __init__(self, output_dir=\"processed_files\", max_workers=None):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.max_workers = max_workers \n",
    "\n",
    "    def process_files_concurrently(self, filepaths, processing_task_func, **logic_kwargs):\n",
    "        \"\"\"\n",
    "        Processes files concurrently using ThreadPoolExecutor.\n",
    "        Uses a specified processing_logic_func for each file.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Starting Concurrent File Processing (ThreadPoolExecutor) ---\")\n",
    "        print(f\"Using processing logic: {processing_task_func.__name__}\")\n",
    "        print(f\"Logic arguments: {logic_kwargs}\")\n",
    "        start_time = time.time()\n",
    "        results = []\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            futures = {\n",
    "                executor.submit(_generic_file_worker, fp, self.output_dir, processing_task_func, **logic_kwargs): fp\n",
    "                for fp in filepaths\n",
    "            }\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                filepath = futures[future]\n",
    "                try:\n",
    "                    result = future.result() \n",
    "                    results.append(result)\n",
    "                except Exception as exc:\n",
    "                    print(f'{filepath} generated an unhandled exception: {exc}')\n",
    "                    results.append({\"filepath\": filepath, \"status\": \"unhandled_error\", \"message\": str(exc)})\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Concurrent processing finished in {end_time - start_time:.2f} seconds.\")\n",
    "        return results\n",
    "\n",
    "# # --- Sequential File Processor (for comparison) ---\n",
    "# class SequentialFileProcessor:\n",
    "#     def __init__(self, output_dir=\"processed_files\"):\n",
    "#         self.output_dir = output_dir\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#     def _sequential_file_worker(self, filepath, output_dir, processing_logic_func, **logic_kwargs):\n",
    "#         base_name = os.path.basename(filepath)\n",
    "#         print(f\"Processing {base_name} sequentially using {processing_logic_func.__name__}...\")\n",
    "#         try:\n",
    "#             os.makedirs(output_dir, exist_ok=True)\n",
    "#             logic_result = processing_logic_func(filepath, **logic_kwargs)\n",
    "            \n",
    "#             final_content = logic_result.get(\"content\", \"No content\")\n",
    "#             status = logic_result.get(\"status\", \"unknown\")\n",
    "#             message = logic_result.get(\"message\", \"No message\")\n",
    "#             content_type = logic_result.get(\"content_type\", \"unknown\")\n",
    "\n",
    "#             processed_data = {\n",
    "#                 \"filename\": base_name,\n",
    "#                 \"status\": status,\n",
    "#                 \"message\": message,\n",
    "#                 \"content_type\": content_type,\n",
    "#                 \"processed_chars\": len(final_content)\n",
    "#             }\n",
    "            \n",
    "#             output_filepath = os.path.join(output_dir, base_name + \".json\")\n",
    "#             with open(output_filepath, 'w', encoding='utf-8') as f_out:\n",
    "#                 json.dump(processed_data, f_out, indent=2)\n",
    "#             print(f\"  [Sequential Worker] Saved result for {base_name}.\")\n",
    "#             return {\"filepath\": filepath, \"status\": status, \"data\": processed_data}\n",
    "#         except Exception as e:\n",
    "#             print(f\"  [Sequential Worker] Error processing or saving result for {base_name}: {e}\")\n",
    "#             return {\"filepath\": filepath, \"status\": \"worker_error\", \"message\": str(e)}\n",
    "\n",
    "#     def process_files_sequentially(self, filepaths, processing_logic_func, **logic_kwargs):\n",
    "#         print(\"\\n--- Starting Sequential File Processing ---\")\n",
    "#         start_time = time.time()\n",
    "#         results = []\n",
    "#         for filepath in filepaths:\n",
    "#             results.append(self._sequential_file_worker(filepath, self.output_dir, processing_logic_func, **logic_kwargs))\n",
    "#         end_time = time.time()\n",
    "#         print(f\"Sequential processing finished in {end_time - start_time:.2f} seconds.\")\n",
    "#         return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625779d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== DEMO 1: Processing PDFs with Markdown Timeout =====\n",
      "\n",
      "--- Starting Concurrent File Processing (ThreadPoolExecutor) ---\n",
      "Using processing logic: _process_pdf_task\n",
      "Logic arguments: {'markdown_timeout_seconds': 1.0}\n",
      "Processing article_0.pdf using _process_pdf_task...\n",
      "Processing article_1.pdf using _process_pdf_task...\n",
      "Processing article_2.pdf using _process_pdf_task...\n",
      "Processing article_3.pdf using _process_pdf_task...\n",
      "  [PDF Logic] Markdown conversion successful for article_1.pdf.\n",
      "  [PDF Logic] Markdown conversion successful for article_0.pdf.\n",
      "  [PDF Logic] Markdown conversion successful for article_2.pdf.\n",
      "  [PDF Logic] Markdown conversion successful for article_3.pdf.\n",
      "  [Generic Worker] Saved result for article_0.pdf.\n",
      "Processing article_4.pdf using _process_pdf_task...\n",
      "  [Generic Worker] Saved result for article_2.pdf.\n",
      "Processing article_5.pdf using _process_pdf_task...\n",
      "  [Generic Worker] Saved result for article_1.pdf.\n",
      "Processing article_6.pdf using _process_pdf_task...\n",
      "  [Generic Worker] Saved result for article_3.pdf.\n",
      "Processing article_7.pdf using _process_pdf_task...\n",
      "  [Markdown Converter] Simulating long Markdown conversion for article_5.pdf...\n",
      "  [PDF Logic] Markdown conversion successful for article_4.pdf.\n",
      "  [PDF Logic] Markdown conversion successful for article_7.pdf.\n",
      "  [PDF Logic] Markdown conversion successful for article_6.pdf.\n",
      "  [Generic Worker] Saved result for article_4.pdf.\n",
      "Processing article_8.pdf using _process_pdf_task...\n",
      "  [Generic Worker] Saved result for article_7.pdf.\n",
      "Processing article_9.pdf using _process_pdf_task...\n",
      "  [Generic Worker] Saved result for article_6.pdf.\n",
      "  [PDF Logic] Markdown conversion successful for article_9.pdf.\n",
      "  [PDF Logic] Markdown conversion successful for article_8.pdf.\n",
      "  [Generic Worker] Saved result for article_8.pdf.\n",
      "  [Generic Worker] Saved result for article_9.pdf.\n",
      "  [PDF Logic] Timeout: Markdown conversion for article_5.pdf took too long (1.0s). Falling back to plain text.\n",
      "  [PDF Logic] Successfully read plain text for article_5.pdf.\n",
      "  [Generic Worker] Saved result for article_5.pdf.\n",
      "Concurrent processing finished in 1.51 seconds.\n",
      "\n",
      "\n",
      "===== DEMO 2: Processing XMLs =====\n",
      "\n",
      "--- Starting Concurrent File Processing (ThreadPoolExecutor) ---\n",
      "Using processing logic: _process_xml_task\n",
      "Logic arguments: {}\n",
      "Processing metadata_0.xml using _process_xml_task...\n",
      "  [XML Logic] Processing XML file: metadata_0.xml...\n",
      "Processing metadata_1.xml using _process_xml_task...\n",
      "  [XML Logic] Processing XML file: metadata_1.xml...\n",
      "Processing metadata_2.xml using _process_xml_task...\n",
      "  [XML Logic] Processing XML file: metadata_2.xml...\n",
      "Processing metadata_3.xml using _process_xml_task...\n",
      "  [XML Logic] Processing XML file: metadata_3.xml...\n",
      "  [Generic Worker] Saved result for metadata_0.xml.\n",
      "Processing metadata_4.xml using _process_xml_task...\n",
      "  [XML Logic] Processing XML file: metadata_4.xml...\n",
      "  [Generic Worker] Saved result for metadata_1.xml.\n",
      "Processing metadata_5.xml using _process_xml_task...\n",
      "  [XML Logic] Processing XML file: metadata_5.xml...\n",
      "  [Generic Worker] Saved result for metadata_2.xml.\n",
      "Processing metadata_6.xml using _process_xml_task...\n",
      "  [Generic Worker] Saved result for metadata_3.xml.\n",
      "Processing metadata_7.xml using _process_xml_task...\n",
      "  [XML Logic] Processing XML file: metadata_6.xml...\n",
      "  [XML Logic] Processing XML file: metadata_7.xml...\n",
      "  [Generic Worker] Saved result for metadata_4.xml.\n",
      "Processing metadata_8.xml using _process_xml_task...\n",
      "  [XML Logic] Processing XML file: metadata_8.xml...\n",
      "  [Generic Worker] Saved result for metadata_5.xml.\n",
      "Processing metadata_9.xml using _process_xml_task...\n",
      "  [Generic Worker] Saved result for metadata_6.xml.\n",
      "  [Generic Worker] Saved result for metadata_7.xml.\n",
      "  [XML Logic] Processing XML file: metadata_9.xml...\n",
      "  [Generic Worker] Saved result for metadata_8.xml.\n",
      "  [Generic Worker] Saved result for metadata_9.xml.\n",
      "Concurrent processing finished in 0.31 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Demonstration ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Create dummy PDF files\n",
    "    dummy_pdf_dir = \"dummy_pdfs\"\n",
    "    os.makedirs(dummy_pdf_dir, exist_ok=True)\n",
    "    dummy_pdf_filepaths = []\n",
    "    for i in range(10):\n",
    "        filepath = os.path.join(dummy_pdf_dir, f\"article_{i}.pdf\")\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"This is the content of PDF article {i}. It has some data related to research. DOI: 10.1234/data.{i}\")\n",
    "        dummy_pdf_filepaths.append(filepath)\n",
    "\n",
    "    # Create dummy XML files\n",
    "    dummy_xml_dir = \"dummy_xmls\"\n",
    "    os.makedirs(dummy_xml_dir, exist_ok=True)\n",
    "    dummy_xml_filepaths = []\n",
    "    for i in range(10):\n",
    "        filepath = os.path.join(dummy_xml_dir, f\"metadata_{i}.xml\")\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"<root><id>{i}</id><title>Metadata for {i}</title></root>\")\n",
    "        dummy_xml_filepaths.append(filepath)\n",
    "\n",
    "    # --- DEMO 1: Process PDFs concurrently with timeout ---\n",
    "    print(\"\\n\\n===== DEMO 1: Processing PDFs with Markdown Timeout =====\")\n",
    "    concurrent_pdf_processor = ConcurrentFileProcessor(max_workers=4) \n",
    "    concurrent_pdf_processor.process_files_concurrently(\n",
    "        dummy_pdf_filepaths,\n",
    "        processing_task_func=_process_pdf_task,\n",
    "        markdown_timeout_seconds=1.0 # Specific argument for PDF logic\n",
    "    )\n",
    "\n",
    "    # --- DEMO 2: Process XMLs concurrently ---\n",
    "    print(\"\\n\\n===== DEMO 2: Processing XMLs =====\")\n",
    "    concurrent_xml_processor = ConcurrentFileProcessor(max_workers=4) \n",
    "    concurrent_xml_processor.process_files_concurrently(\n",
    "        dummy_xml_filepaths,\n",
    "        processing_task_func=_process_xml_task # No specific kwargs needed for XML logic\n",
    "    )\n",
    "\n",
    "    # # --- DEMO 3: Sequential PDF Processing (for comparison) ---\n",
    "    # print(\"\\n\\n===== DEMO 3: Sequential PDF Processing =====\")\n",
    "    # seq_pdf_processor = SequentialFileProcessor()\n",
    "    # seq_pdf_processor.process_files_sequentially(\n",
    "    #     dummy_pdf_filepaths,\n",
    "    #     processing_logic_func=_process_pdf_logic,\n",
    "    #     markdown_timeout_seconds=3.0\n",
    "    # )\n",
    "\n",
    "    # Clean up dummy files and directories\n",
    "    for fp in dummy_pdf_filepaths:\n",
    "        os.remove(fp)\n",
    "    if os.path.exists(dummy_pdf_dir):\n",
    "        os.rmdir(dummy_pdf_dir)\n",
    "\n",
    "    for fp in dummy_xml_filepaths:\n",
    "        os.remove(fp)\n",
    "    if os.path.exists(dummy_xml_dir):\n",
    "        os.rmdir(dummy_xml_dir)\n",
    "    \n",
    "    # Clean up processed_files directory\n",
    "    if os.path.exists(\"processed_files\"):\n",
    "        for f in os.listdir(\"processed_files\"):\n",
    "            os.remove(os.path.join(\"processed_files\", f))\n",
    "        os.rmdir(\"processed_files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
